{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mscholl96/mad-recime/blob/network_CVAE/network/CVAE/cvae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zapniU98wzMW"
      },
      "source": [
        "# Conditional variational autoencoder\n",
        "Variational autoencoder for tabular data, oriented upon: https://lschmiddey.github.io/fastpages_/2021/03/14/tabular-data-variational-autoencoder.html \n",
        "\n",
        "Adopted with one hot encoding for tabular data\n",
        "## Load Json Database of recipes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zTkqc12wzMc",
        "outputId": "36816fdc-9976-4280-f6fc-d2e5783b1894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataPath = '/content/drive/MyDrive/TP2/Datasets/Recipe1M/2022_02_11/recipes_valid_0.pkl'\n",
        "import sys\n",
        "sys.path.append(dataPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e61O0YAwzMd"
      },
      "outputs": [],
      "source": [
        "dataPath = 'data/recipes_valid_0.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkkejbegwzMd",
        "outputId": "181c1551-cb15-4e17-d488-c72994a2294f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['title', 'ingredients', 'instructions'], dtype='object')\n",
            "100000\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "with open(dataPath, 'rb') as f:\n",
        "    pklData = pd.DataFrame(pickle.load(f))\n",
        "\n",
        "print(pklData.keys())\n",
        "print(len(pklData))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3woTtbf9wzMe"
      },
      "source": [
        "## Convert list of ingredients to pandas dataframe and one hot encode the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7kjo-mMGYBU",
        "outputId": "d2672c37-3e25-4f44-e0c0-68ed7b1d90bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word2vec\n",
            "  Downloading word2vec-0.11.1.tar.gz (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 795 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.21.5)\n",
            "Building wheels for collected packages: word2vec\n",
            "  Building wheel for word2vec (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2vec: filename=word2vec-0.11.1-py2.py3-none-any.whl size=156420 sha256=3591c5f1338e1124c0fe16fa803900036c78cf7e01775c3967817f5703020e3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/c0/d4/29d797817e268124a32b6cf8beb8b8fe87b86f099d5a049e61\n",
            "Successfully built word2vec\n",
            "Installing collected packages: word2vec\n",
            "Successfully installed word2vec-0.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d1HzhTL5EUPd"
      },
      "outputs": [],
      "source": [
        "from ReciMePreprocessor import ReciMePreprocessor\n",
        "\n",
        "preprocessor = ReciMePreprocessor('/content/drive/MyDrive/TP2/Datasets/Recipe1M/vocab.bin')\n",
        "#pklData = pklData[:2000]\n",
        "out = preprocessor.preProcessInput(pklData['ingredients'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBKbgRf-wzMg"
      },
      "source": [
        "## VAE\n",
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5CjNvLnwzMg",
        "outputId": "5a8e09d8-a420-474d-8dc6-bd7c746d13f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Import pytorch dependencies\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Import additional libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import custom autoencoder\n",
        "from ReciMeEncoder import ReciMeEncoder, RmeParameters\n",
        "from ReciMeEncoder_unstacked import ReciMeEncoder_unstacked\n",
        "\n",
        "# Import custom helper functions\n",
        "from networkUtils import DataBuilder, standardize_data\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3qKdykwCws66"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.mse_loss = nn.MSELoss(reduction='none')\n",
        "    \n",
        "    def forward(self, x_recon, x, mu, logvar):\n",
        "        loss_MSE = self.mse_loss(x_recon, x).sum(axis=1)\n",
        "        loss_MSE = loss_MSE.mean()\n",
        "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu**2 - torch.exp(logvar), axis=1)\n",
        "        loss_KLD = loss_KLD.mean()\n",
        "\n",
        "        return loss_MSE, loss_KLD, loss_MSE + loss_KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j2suV_iWws66",
        "outputId": "68805d5b-92c2-4b09-e187-0312beca15f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "loss = CustomLoss()\n",
        "\n",
        "mat1 = torch.Tensor(np.zeros((1024,6400)))\n",
        "mat2 = torch.Tensor(np.ones((1024,6400)))\n",
        "\n",
        "mse, kld, l = loss(mat2, mat1, torch.tensor(np.zeros((1024,128))), torch.tensor(np.zeros((1024,128))))\n",
        "mse.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR6u1q3lwzMg"
      },
      "source": [
        "### Setup Datasets + Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yle-AZJ6wzMh"
      },
      "outputs": [],
      "source": [
        "# One hot encoding without embedding and using sparse frame\n",
        "train_data, test_data, scaler =  standardize_data(out)\n",
        "batch_size = 512\n",
        "# Train/Testdataset split is defined in the DataBuilder\n",
        "traindata_set=DataBuilder(train_data, standardizer=scaler)\n",
        "testdata_set=DataBuilder(test_data, standardizer=scaler)\n",
        "# Definition of batches\n",
        "trainloader=DataLoader(dataset=traindata_set,batch_size=batch_size)\n",
        "testloader=DataLoader(dataset=testdata_set,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oD_T2VYFwzMh",
        "outputId": "843e505e-637f-4b68-aa4f-4d1a9f1e0814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReciMeEncoder(\n",
            "  (encoderStack): Sequential(\n",
            "    (0): _ReLUBatchNormLinear(\n",
            "      (layer): Sequential(\n",
            "        (0): Linear(in_features=6360, out_features=10000, bias=True)\n",
            "        (1): BatchNorm1d(10000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): _ReLUBatchNormLinear(\n",
            "      (layer): Sequential(\n",
            "        (0): Linear(in_features=10000, out_features=7000, bias=True)\n",
            "        (1): BatchNorm1d(7000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (2): _ReLUBatchNormLinear(\n",
            "      (layer): Sequential(\n",
            "        (0): Linear(in_features=7000, out_features=4000, bias=True)\n",
            "        (1): BatchNorm1d(4000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (3): _ReLUBatchNormLinear(\n",
            "      (layer): Sequential(\n",
            "        (0): Linear(in_features=4000, out_features=2500, bias=True)\n",
            "        (1): BatchNorm1d(2500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (muStack): Linear(in_features=2500, out_features=2500, bias=True)\n",
            "  (logvarStack): Linear(in_features=2500, out_features=2500, bias=True)\n",
            "  (decoderStack): Sequential(\n",
            "    (0): _ReLUBatchNormLinear(\n",
            "      (layer): Sequential(\n",
            "        (0): Linear(in_features=2500, out_features=4000, bias=True)\n",
            "        (1): BatchNorm1d(4000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): _ReLUBatchNormLinear(\n",
            "      (layer): Sequential(\n",
            "        (0): Linear(in_features=4000, out_features=7000, bias=True)\n",
            "        (1): BatchNorm1d(7000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (2): _ReLUBatchNormLinear(\n",
            "      (layer): Sequential(\n",
            "        (0): Linear(in_features=7000, out_features=10000, bias=True)\n",
            "        (1): BatchNorm1d(10000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (3): Linear(in_features=10000, out_features=6360, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "params = RmeParameters(testdata_set.x.shape[1], 10000, 7000, 4000, 2500)\n",
        "\n",
        "model = ReciMeEncoder(params).to(device)\n",
        "print(model)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_mse = CustomLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH1FyiqXwzMi"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zkHZycy2wzMi"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "log_interval = 5\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "train_losses_MSE = []\n",
        "train_losses_KLD = []\n",
        "test_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_Nw6yXRbws6-"
      },
      "outputs": [],
      "source": [
        "def train_otherloss(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, data in enumerate(trainloader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss_MSE, loss_KLD, loss = loss_mse(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        loss_itm = loss.item()\n",
        "        train_loss = loss_itm\n",
        "        train_loss_MSE = loss_MSE.item()\n",
        "        train_loss_KLD = loss_KLD.item()\n",
        "        train_losses.append(train_loss)\n",
        "        train_losses_MSE.append(train_loss_MSE)\n",
        "        train_losses_KLD.append(train_loss_KLD)\n",
        "        optimizer.step()\n",
        "    if epoch % log_interval == 0:        \n",
        "        print('====> Epoch: {} Average training loss: {:.5f}, MSE: {:.5f}, KLD: {:.5f}'.format(\n",
        "            epoch, train_loss, \n",
        "            train_loss_MSE , \n",
        "            train_loss_KLD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2ROmciOcws6_"
      },
      "outputs": [],
      "source": [
        "def test_otherloss(epoch):\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(testloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            loss_MSE, loss_KLD, loss = loss_mse(recon_batch, data, mu, logvar)\n",
        "            loss_itm = loss.item()\n",
        "            test_loss = loss_itm\n",
        "            test_loss_MSE = loss_MSE\n",
        "            test_loss_KLD = loss_KLD\n",
        "            test_losses.append(test_loss)\n",
        "        if epoch % log_interval == 0:        \n",
        "            print('====> Epoch: {} Average test loss: {:.4f}, MSE: {:.4f}, KLD: {:.4f}'.format(\n",
        "                epoch, test_loss, \n",
        "                test_loss_MSE, \n",
        "                test_loss_KLD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dyZzQCtwwzMj"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_loss_MSE = 0\n",
        "    train_loss_KLD = 0\n",
        "    for batch_idx, data in enumerate(trainloader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss_MSE, loss_KLD, loss = loss_mse(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        loss_itm = loss.item()\n",
        "        train_loss += loss_itm\n",
        "        train_loss_MSE += loss_MSE.item()\n",
        "        train_loss_KLD += loss_KLD.item()\n",
        "        optimizer.step()\n",
        "    if epoch % log_interval == 0:        \n",
        "        print('====> Epoch: {} Average training loss: {:.5f}, MSE: {:.5f}, KLD: {:.5f}'.format(\n",
        "            epoch, train_loss / len(trainloader.dataset), \n",
        "            train_loss_MSE / len(trainloader.dataset), \n",
        "            train_loss_KLD / len(trainloader.dataset)))\n",
        "        train_losses.append(train_loss / len(trainloader.dataset))\n",
        "        train_losses_MSE.append(train_loss_MSE / len(trainloader.dataset))\n",
        "        train_losses_KLD.append(train_loss_KLD / len(trainloader.dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NtNNh601wzMj"
      },
      "outputs": [],
      "source": [
        "def test(epoch):\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0\n",
        "        test_loss_MSE = 0\n",
        "        test_loss_KLD = 0\n",
        "        for batch_idx, data in enumerate(testloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            loss_MSE, loss_KLD, loss = loss_mse(recon_batch, data, mu, logvar)\n",
        "            loss_itm = loss.item()\n",
        "            test_loss += loss_itm\n",
        "            test_loss_MSE += loss_MSE.item()\n",
        "            test_loss_KLD += loss_KLD.item()\n",
        "        if epoch % log_interval == 0:        \n",
        "            print('====> Epoch: {} Average test loss: {:.4f}, MSE: {:.4f}, KLD: {:.4f}'.format(\n",
        "                epoch, test_loss / len(testloader.dataset), \n",
        "                test_loss_MSE / len(testloader.dataset), \n",
        "                test_loss_KLD / len(testloader.dataset)))\n",
        "            test_losses.append(test_loss / len(testloader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ascBDVv1wzMk",
        "outputId": "6df5452d-722d-4631-cdbf-851fedc16287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Epoch: 5 Average training loss: 10.84688, MSE: 10.36403, KLD: 0.48285\n",
            "====> Epoch: 5 Average test loss: 11.0215, MSE: 10.6916, KLD: 0.3298\n",
            "====> Epoch: 10 Average training loss: 10.51210, MSE: 10.15926, KLD: 0.35284\n",
            "====> Epoch: 10 Average test loss: 12.3587, MSE: 12.0316, KLD: 0.3271\n",
            "====> Epoch: 15 Average training loss: 10.24858, MSE: 10.07606, KLD: 0.17252\n",
            "====> Epoch: 15 Average test loss: 11.1687, MSE: 11.0133, KLD: 0.1554\n",
            "====> Epoch: 20 Average training loss: 9.97325, MSE: 9.86850, KLD: 0.10475\n",
            "====> Epoch: 20 Average test loss: 12.3593, MSE: 12.2169, KLD: 0.1424\n",
            "====> Epoch: 25 Average training loss: 10.00605, MSE: 9.88934, KLD: 0.11671\n",
            "====> Epoch: 25 Average test loss: 10.0460, MSE: 9.9738, KLD: 0.0723\n",
            "====> Epoch: 30 Average training loss: 9.54085, MSE: 9.48066, KLD: 0.06019\n",
            "====> Epoch: 30 Average test loss: 10.0033, MSE: 9.9469, KLD: 0.0565\n",
            "====> Epoch: 35 Average training loss: 9.83066, MSE: 9.73204, KLD: 0.09862\n",
            "====> Epoch: 35 Average test loss: 10.0895, MSE: 9.9205, KLD: 0.1691\n",
            "====> Epoch: 40 Average training loss: 9.57805, MSE: 9.51311, KLD: 0.06494\n",
            "====> Epoch: 40 Average test loss: 10.3120, MSE: 10.2463, KLD: 0.0657\n",
            "====> Epoch: 45 Average training loss: 10.05463, MSE: 9.92283, KLD: 0.13180\n",
            "====> Epoch: 45 Average test loss: 11.0285, MSE: 10.9128, KLD: 0.1156\n",
            "====> Epoch: 50 Average training loss: 9.27531, MSE: 9.23044, KLD: 0.04488\n",
            "====> Epoch: 50 Average test loss: 9.6622, MSE: 9.6168, KLD: 0.0454\n",
            "====> Epoch: 55 Average training loss: 9.23978, MSE: 9.17342, KLD: 0.06636\n",
            "====> Epoch: 55 Average test loss: 9.6341, MSE: 9.5657, KLD: 0.0683\n",
            "====> Epoch: 60 Average training loss: 9.08307, MSE: 9.03098, KLD: 0.05209\n",
            "====> Epoch: 60 Average test loss: 9.6303, MSE: 9.5788, KLD: 0.0515\n",
            "====> Epoch: 65 Average training loss: 9.01717, MSE: 8.95852, KLD: 0.05865\n",
            "====> Epoch: 65 Average test loss: 9.5282, MSE: 9.4753, KLD: 0.0529\n",
            "====> Epoch: 70 Average training loss: 8.95626, MSE: 8.88801, KLD: 0.06825\n",
            "====> Epoch: 70 Average test loss: 9.4269, MSE: 9.3669, KLD: 0.0600\n",
            "====> Epoch: 75 Average training loss: 8.85079, MSE: 8.78727, KLD: 0.06352\n",
            "====> Epoch: 75 Average test loss: 9.4019, MSE: 9.3387, KLD: 0.0632\n",
            "====> Epoch: 80 Average training loss: 8.77380, MSE: 8.70997, KLD: 0.06383\n",
            "====> Epoch: 80 Average test loss: 9.2955, MSE: 9.2325, KLD: 0.0630\n",
            "====> Epoch: 85 Average training loss: 8.72204, MSE: 8.63871, KLD: 0.08333\n",
            "====> Epoch: 85 Average test loss: 9.2978, MSE: 9.2295, KLD: 0.0684\n",
            "====> Epoch: 90 Average training loss: 8.59254, MSE: 8.52305, KLD: 0.06949\n",
            "====> Epoch: 90 Average test loss: 9.1884, MSE: 9.1209, KLD: 0.0676\n",
            "====> Epoch: 95 Average training loss: 8.52524, MSE: 8.44353, KLD: 0.08171\n",
            "====> Epoch: 95 Average test loss: 9.1584, MSE: 9.0843, KLD: 0.0741\n",
            "====> Epoch: 100 Average training loss: 8.39836, MSE: 8.31672, KLD: 0.08164\n",
            "====> Epoch: 100 Average test loss: 9.1380, MSE: 9.0580, KLD: 0.0799\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1,epochs+1):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NyRyzB8zws7B",
        "outputId": "408b614a-abeb-4ebc-cb16-a4b66597f8cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdf51ff52d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses)\n",
        "plt.plot(train_losses_MSE)\n",
        "plt.plot(train_losses_KLD)\n",
        "plt.legend(['Train', 'Train_MSE', 'Train_KLD'])\n",
        "#plt.ylim([0,100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "stl8-ACfwzMk",
        "outputId": "917e51aa-e9fd-42bb-b879-e47f22f3e3bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdf5d775e50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(test_losses)\n",
        "plt.plot(train_losses)\n",
        "plt.legend(['Test', 'Train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYvu9HekwzMm"
      },
      "source": [
        "### Draw random samples form latent space and generate new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xxoWJ_IWEUPj"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(testloader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o-l_00KswzMn"
      },
      "outputs": [],
      "source": [
        "sigma = torch.exp(logvar/2)\n",
        "# sample z from q\n",
        "no_samples = 20\n",
        "q = torch.distributions.Normal(mu.mean(axis=0), sigma.mean(axis=0))\n",
        "z = q.rsample(sample_shape=torch.Size([no_samples]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hXeISFOtwzMn"
      },
      "outputs": [],
      "source": [
        "scaler = trainloader.dataset.standardizer\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model.decode(z).cpu().numpy()\n",
        "\n",
        "fake_data = scaler.inverse_transform(pred)\n",
        "df_fake = pd.DataFrame(fake_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "t36HAyPorImY",
        "outputId": "12e13e53-45cd-46dc-de18-a522107ab891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3adc9ea2-259f-4a61-a8bb-0e7e2d3ce491\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>6350</th>\n",
              "      <th>6351</th>\n",
              "      <th>6352</th>\n",
              "      <th>6353</th>\n",
              "      <th>6354</th>\n",
              "      <th>6355</th>\n",
              "      <th>6356</th>\n",
              "      <th>6357</th>\n",
              "      <th>6358</th>\n",
              "      <th>6359</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-40.899158</td>\n",
              "      <td>13.102093</td>\n",
              "      <td>-73.577713</td>\n",
              "      <td>-82.653664</td>\n",
              "      <td>13.583007</td>\n",
              "      <td>26.483810</td>\n",
              "      <td>4.119952</td>\n",
              "      <td>12.353475</td>\n",
              "      <td>-8.538115</td>\n",
              "      <td>-25.258942</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038755</td>\n",
              "      <td>0.037693</td>\n",
              "      <td>0.020685</td>\n",
              "      <td>-0.040307</td>\n",
              "      <td>0.058093</td>\n",
              "      <td>-0.111225</td>\n",
              "      <td>-0.039768</td>\n",
              "      <td>-0.030146</td>\n",
              "      <td>-0.035825</td>\n",
              "      <td>0.073516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50.178753</td>\n",
              "      <td>3.940034</td>\n",
              "      <td>6.853186</td>\n",
              "      <td>15.064278</td>\n",
              "      <td>25.867081</td>\n",
              "      <td>-10.794014</td>\n",
              "      <td>-2.811655</td>\n",
              "      <td>5.676308</td>\n",
              "      <td>1.816841</td>\n",
              "      <td>18.201195</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.019991</td>\n",
              "      <td>0.023966</td>\n",
              "      <td>0.015217</td>\n",
              "      <td>-0.021757</td>\n",
              "      <td>0.045798</td>\n",
              "      <td>-0.071661</td>\n",
              "      <td>-0.022350</td>\n",
              "      <td>-0.021869</td>\n",
              "      <td>-0.025966</td>\n",
              "      <td>0.047028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-52.502029</td>\n",
              "      <td>-50.674248</td>\n",
              "      <td>-40.677860</td>\n",
              "      <td>-31.987591</td>\n",
              "      <td>32.910072</td>\n",
              "      <td>-43.357807</td>\n",
              "      <td>7.553607</td>\n",
              "      <td>-9.793768</td>\n",
              "      <td>-17.457294</td>\n",
              "      <td>-5.863964</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026833</td>\n",
              "      <td>0.033370</td>\n",
              "      <td>0.016745</td>\n",
              "      <td>-0.035986</td>\n",
              "      <td>0.066069</td>\n",
              "      <td>-0.115142</td>\n",
              "      <td>-0.035795</td>\n",
              "      <td>-0.030272</td>\n",
              "      <td>-0.035018</td>\n",
              "      <td>0.078438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.017576</td>\n",
              "      <td>8.196781</td>\n",
              "      <td>8.738047</td>\n",
              "      <td>10.651892</td>\n",
              "      <td>1.584730</td>\n",
              "      <td>0.864948</td>\n",
              "      <td>1.810024</td>\n",
              "      <td>2.500293</td>\n",
              "      <td>0.944762</td>\n",
              "      <td>5.853861</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.021209</td>\n",
              "      <td>0.025383</td>\n",
              "      <td>0.017370</td>\n",
              "      <td>-0.025804</td>\n",
              "      <td>0.048614</td>\n",
              "      <td>-0.077501</td>\n",
              "      <td>-0.023757</td>\n",
              "      <td>-0.022041</td>\n",
              "      <td>-0.028485</td>\n",
              "      <td>0.051506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.757931</td>\n",
              "      <td>8.138694</td>\n",
              "      <td>-6.592222</td>\n",
              "      <td>-3.561291</td>\n",
              "      <td>81.288490</td>\n",
              "      <td>-17.349588</td>\n",
              "      <td>18.657906</td>\n",
              "      <td>22.497259</td>\n",
              "      <td>26.508406</td>\n",
              "      <td>33.977726</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039651</td>\n",
              "      <td>0.037043</td>\n",
              "      <td>0.019965</td>\n",
              "      <td>-0.026270</td>\n",
              "      <td>0.068334</td>\n",
              "      <td>-0.099510</td>\n",
              "      <td>-0.037570</td>\n",
              "      <td>-0.030885</td>\n",
              "      <td>-0.031552</td>\n",
              "      <td>0.072102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6360 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3adc9ea2-259f-4a61-a8bb-0e7e2d3ce491')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3adc9ea2-259f-4a61-a8bb-0e7e2d3ce491 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3adc9ea2-259f-4a61-a8bb-0e7e2d3ce491');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0          1          2          3          4          5     \\\n",
              "0 -40.899158  13.102093 -73.577713 -82.653664  13.583007  26.483810   \n",
              "1  50.178753   3.940034   6.853186  15.064278  25.867081 -10.794014   \n",
              "2 -52.502029 -50.674248 -40.677860 -31.987591  32.910072 -43.357807   \n",
              "3  21.017576   8.196781   8.738047  10.651892   1.584730   0.864948   \n",
              "4  41.757931   8.138694  -6.592222  -3.561291  81.288490 -17.349588   \n",
              "\n",
              "        6          7          8          9     ...      6350      6351  \\\n",
              "0   4.119952  12.353475  -8.538115 -25.258942  ... -0.038755  0.037693   \n",
              "1  -2.811655   5.676308   1.816841  18.201195  ... -0.019991  0.023966   \n",
              "2   7.553607  -9.793768 -17.457294  -5.863964  ... -0.026833  0.033370   \n",
              "3   1.810024   2.500293   0.944762   5.853861  ... -0.021209  0.025383   \n",
              "4  18.657906  22.497259  26.508406  33.977726  ... -0.039651  0.037043   \n",
              "\n",
              "       6352      6353      6354      6355      6356      6357      6358  \\\n",
              "0  0.020685 -0.040307  0.058093 -0.111225 -0.039768 -0.030146 -0.035825   \n",
              "1  0.015217 -0.021757  0.045798 -0.071661 -0.022350 -0.021869 -0.025966   \n",
              "2  0.016745 -0.035986  0.066069 -0.115142 -0.035795 -0.030272 -0.035018   \n",
              "3  0.017370 -0.025804  0.048614 -0.077501 -0.023757 -0.022041 -0.028485   \n",
              "4  0.019965 -0.026270  0.068334 -0.099510 -0.037570 -0.030885 -0.031552   \n",
              "\n",
              "       6359  \n",
              "0  0.073516  \n",
              "1  0.047028  \n",
              "2  0.078438  \n",
              "3  0.051506  \n",
              "4  0.072102  \n",
              "\n",
              "[5 rows x 6360 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df_fake.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQxp_k9FEUPk",
        "outputId": "4330329c-8e44-4da6-f921-27b4cfbf55cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 6360)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(fake_data.shape)\n",
        "print(type(fake_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fGIuz8vJEUPk"
      },
      "outputs": [],
      "source": [
        "def inverseOneHotEncoding(encoded: np.ndarray, dictionary: dict) -> np.ndarray:\n",
        "    output = []\n",
        "    for row in encoded:\n",
        "        rowTransformed = np.reshape(row, (20,-1))\n",
        "        rowString = []\n",
        "        indexTransformed = np.argmax(rowTransformed, axis=1) + 1\n",
        "        for index in indexTransformed:\n",
        "            if (index in dictionary.values()):\n",
        "                rowString.append(list(dictionary.keys())[list(dictionary.values()).index(index)])\n",
        "            else:\n",
        "                rowString.append(\"\")\n",
        "        output.append(rowString)\n",
        "    return np.array(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cX5P1wV6EUPl"
      },
      "outputs": [],
      "source": [
        "def inverseEmbedding(embedded: np.ndarray, dictionary: dict) -> np.ndarray:\n",
        "    output = []\n",
        "    for row in embedded:\n",
        "        outputRows = []\n",
        "        for rowTransformed in np.reshape(row, (20,-1)):\n",
        "            rowTransformed = torch.Tensor(rowTransformed)\n",
        "            distance = torch.norm(preprocessor.emb.weight.data - rowTransformed, dim=1)\n",
        "            nearest = torch.argmin(distance)\n",
        "            index = nearest.item()\n",
        "            if index:\n",
        "                outputRows.append(list(dictionary.keys())[list(dictionary.values()).index(index)])\n",
        "            else:\n",
        "                outputRows.append(\"\")\n",
        "        output.append(outputRows)\n",
        "\n",
        "    return np.array(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "nz90yVggEUPm",
        "outputId": "d18f2f2c-69be-4443-9e42-3fce93884071"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dd8ae1e8-b13e-4c2f-8365-152315403d71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount</th>\n",
              "      <th>unit</th>\n",
              "      <th>ingredient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-40.89916</td>\n",
              "      <td>pound-mass</td>\n",
              "      <td>eggs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.102093</td>\n",
              "      <td>cup</td>\n",
              "      <td>brown_sugar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-73.57771</td>\n",
              "      <td></td>\n",
              "      <td>flour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-82.65366</td>\n",
              "      <td></td>\n",
              "      <td>onions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.583007</td>\n",
              "      <td></td>\n",
              "      <td>garlic_cloves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>26.48381</td>\n",
              "      <td>teaspoon</td>\n",
              "      <td>pepper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.1199517</td>\n",
              "      <td>teaspoon</td>\n",
              "      <td>fistful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12.353475</td>\n",
              "      <td>cup</td>\n",
              "      <td>nor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-8.538115</td>\n",
              "      <td>cup</td>\n",
              "      <td>vanilla_extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-25.258942</td>\n",
              "      <td>cup</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-27.806328</td>\n",
              "      <td>tablespoon</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-17.894777</td>\n",
              "      <td>teaspoon</td>\n",
              "      <td>salt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-8.575244</td>\n",
              "      <td>teaspoon</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-9.426775</td>\n",
              "      <td>teaspoon</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.050723772</td>\n",
              "      <td>gallon</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-8.161006</td>\n",
              "      <td></td>\n",
              "      <td>salt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-3.6638234</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-3.992887</td>\n",
              "      <td>package</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-6.45642</td>\n",
              "      <td>drop</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-4.688241</td>\n",
              "      <td>package</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd8ae1e8-b13e-4c2f-8365-152315403d71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd8ae1e8-b13e-4c2f-8365-152315403d71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd8ae1e8-b13e-4c2f-8365-152315403d71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          amount        unit       ingredient\n",
              "0      -40.89916  pound-mass             eggs\n",
              "1      13.102093         cup      brown_sugar\n",
              "2      -73.57771                        flour\n",
              "3      -82.65366                       onions\n",
              "4      13.583007                garlic_cloves\n",
              "5       26.48381    teaspoon           pepper\n",
              "6      4.1199517    teaspoon          fistful\n",
              "7      12.353475         cup              nor\n",
              "8      -8.538115         cup  vanilla_extract\n",
              "9     -25.258942         cup                 \n",
              "10    -27.806328  tablespoon                 \n",
              "11    -17.894777    teaspoon             salt\n",
              "12     -8.575244    teaspoon                 \n",
              "13     -9.426775    teaspoon                 \n",
              "14  -0.050723772      gallon                 \n",
              "15     -8.161006                         salt\n",
              "16    -3.6638234                             \n",
              "17     -3.992887     package                 \n",
              "18      -6.45642        drop                 \n",
              "19     -4.688241     package                 "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "def decodeOutput(output: np.ndarray):\n",
        "    # Split output into amounts, units and ingredients \n",
        "    amounts = output[:, :20]\n",
        "    amountColumns = ['amount_' + str(sub) for sub in list(range(0,20))]\n",
        "    units = output[:, 20:len(preprocessor.unitDict)*20+20]\n",
        "    unitColumns = ['unit_' + str(sub) for sub in list(range(0,20))]\n",
        "    ingredients = output[:, len(preprocessor.unitDict)*20+20:]\n",
        "    ingredientColumns = ['ingredient_' + str(sub) for sub in list(range(0,20))]\n",
        "    unitsDecoded = inverseOneHotEncoding(units, preprocessor.unitDict)\n",
        "    ingredientsDecoded = inverseEmbedding(ingredients, preprocessor.ingredientDict)\n",
        "    outputFrame = []\n",
        "    for index in range(len(amounts)):\n",
        "        array = np.stack((amounts[index], unitsDecoded[index], ingredientsDecoded[index]),axis=1)\n",
        "        outputFrame.append(pd.DataFrame(array, columns=[\"amount\", \"unit\", \"ingredient\"]))\n",
        "    return outputFrame\n",
        "\n",
        "df = decodeOutput(fake_data)\n",
        "df[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "2dh-6TeiEUPm",
        "outputId": "fd748f0e-837c-497e-aed3-4e5f3408f074"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-855489e86102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataEmbedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreProcessInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataEmbedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ReciMeEncoder_unstacked.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparametrize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ReciMeEncoder_unstacked.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mlatent_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoderStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmuStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogvarStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
          ]
        }
      ],
      "source": [
        "data = pklData[:1]['ingredients']\n",
        "\n",
        "dataEmbedded = np.array(preprocessor.preProcessInput(data))\n",
        "\n",
        "y, mu, logvar = model(dataEmbedded)\n",
        "\n",
        "\n",
        "dataReconverted = decodeOutput(dataEmbedded)\n",
        "pd.concat([dataReconverted[0], data[0].add_prefix(\"orig_\")], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6pqjuU7EUPm",
        "outputId": "d6a17114-e7be-4141-950a-430664a20db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dry_dill_weed\n",
            "dill_weed\n",
            "weed\n"
          ]
        }
      ],
      "source": [
        "string = \"dry dill weed\"\n",
        "name_words = string.lower().split(' ')\n",
        "for i in range(len(name_words)):\n",
        "    print('_'.join(name_words[i:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlXnAae3EUPn",
        "outputId": "f375967d-b038-47e4-a679-74c9560579aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 100])\n",
            "torch.Size([1000, 100])\n"
          ]
        }
      ],
      "source": [
        "embeddings = torch.nn.Embedding(1000, 100)\n",
        "my_sample = torch.randn(1, 100)\n",
        "distance = torch.norm(embeddings.weight.data - my_sample, dim=1)\n",
        "nearest = torch.argmin(distance)\n",
        "print(my_sample.shape)\n",
        "print(embeddings.weight.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "NQ6kN0hQwzMo",
        "outputId": "24965326-6d74-4404-b2b2-a17b3d31c806"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-48604f2e68b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_fake_stripped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropColumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_fake_stripped_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_fake_stripped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframeStripped_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_fake_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_fake\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropColumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_fake_stripped_decoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_fake_decoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dropColumns' is not defined"
          ]
        }
      ],
      "source": [
        "df_fake_stripped = df_fake.drop(columns=dropColumns)\n",
        "df_fake_stripped_decoded = pd.DataFrame(data=enc.inverse_transform(df_fake_stripped), columns=frameStripped_cols)\n",
        "df_fake_decoded = pd.concat([df_fake[dropColumns], df_fake_stripped_decoded], axis=1)\n",
        "df_fake_decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbh1MGDCwzMo"
      },
      "outputs": [],
      "source": [
        "class Ingredient:\n",
        "    def __init__(self, amount, unit, ingredient) -> None:\n",
        "        self.amount = amount\n",
        "        self.unit = unit\n",
        "        self.ingredient = ingredient\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"\\nAmount: \" + str(self.amount) + \"\\n Unit: \" + str(self.unit) + \"\\n Ingredient: \" + str(self.ingredient)\n",
        "\n",
        "recipes = []\n",
        "lenIngredients = int(len(df_fake_decoded.columns)/3)\n",
        "for value in df_fake_decoded.values:\n",
        "    ingredients = []\n",
        "    for index in range(0,lenIngredients):\n",
        "        frame = []\n",
        "        frame.append(value[index])\n",
        "        frame.append(value[(2*index)+lenIngredients])\n",
        "        frame.append(value[(2*index+1)+lenIngredients])\n",
        "        ingredients.append(frame)\n",
        "    recipes.append(ingredients)\n",
        "\n",
        "pd.DataFrame(recipes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNbXCbGPwzMp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "cvae.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "bb875f4a3a3b27879a30076b84fa05114b199e04f8f3aeee4f2ba73a2af38a98"
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit ('recime': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}