{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mscholl96/mad-recime/blob/network_LSTM/network/LSTM/instrGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzCPQy6dlIJK"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R3yLJ1_xBA2"
      },
      "source": [
        "## Basic includes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XN0Eb2xPKgV",
        "outputId": "e2248dec-5930-4cc3-aa93-dc2f184e9c45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 1.67 ms (started: 2022-03-22 21:36:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE0vTXeQQv_A",
        "outputId": "2b00188e-32a7-4665-a205-17dc4d782c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting word2vec\n",
            "  Downloading word2vec-0.11.1.tar.gz (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 43.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 50.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30 kB 57.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.21.5)\n",
            "Building wheels for collected packages: word2vec\n",
            "  Building wheel for word2vec (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2vec: filename=word2vec-0.11.1-py2.py3-none-any.whl size=164791 sha256=917ed518cab60707885041dd61b49d676144546134d36eae7e5d54f30e880b30\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/c0/d4/29d797817e268124a32b6cf8beb8b8fe87b86f099d5a049e61\n",
            "Successfully built word2vec\n",
            "Installing collected packages: word2vec\n",
            "Successfully installed word2vec-0.11.1\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 52.7 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.5)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 86.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 80.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.6.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 97.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.11.3)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (3.0.7)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Installing collected packages: deprecated, redis, grpcio, tensorboardX, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed deprecated-1.2.13 grpcio-1.43.0 ray-1.11.0 redis-4.1.4 tensorboardX-2.5\n",
            "time: 23.9 s (started: 2022-03-22 21:36:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install word2vec\n",
        "!pip install ray[tune]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9lWMi0pxADs",
        "outputId": "82cb632b-6ae9-48d0-9a4b-0e937798d725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 283 ms (started: 2022-03-22 21:36:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import word2vec\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "\n",
        "import glob\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06MHgolQxDOM",
        "outputId": "78e0000d-a14d-4715-87f1-92a57bb34e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "time: 3min 15s (started: 2022-03-22 21:36:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "dataPath = '/content/drive/MyDrive/TP2/Datasets/Recipe1M/'\n",
        "import sys\n",
        "sys.path.append(dataPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEaAmmFMx-FW"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cLUewNUx_uv",
        "outputId": "e23283d7-0693-458d-d640-e5f826830af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 945 µs (started: 2022-03-22 21:40:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "TIMESTAMP = '2022_03_19'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UOcytg8qyAvB",
        "outputId": "6190169e-5aa6-4fa6-f1d7-6d2df65ad7e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bd486a46-b9bf-45b5-b830-7cb1b000d3b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>instructions</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000033e39b</th>\n",
              "      <td>Dilly Macaroni Salad Recipe</td>\n",
              "      <td>amount        unit       ingredient\n",
              "0    1....</td>\n",
              "      <td>0    Cook macaroni according to package direct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000035f7ed</th>\n",
              "      <td>Gazpacho</td>\n",
              "      <td>amount unit          ingredient\n",
              "0     8.0  ...</td>\n",
              "      <td>0    Add the tomatoes to a food processor with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00003a70b1</th>\n",
              "      <td>Crunchy Onion Potato Bake</td>\n",
              "      <td>amount   unit             ingredient\n",
              "0    2...</td>\n",
              "      <td>0              Preheat oven to 350 degrees Fah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00004320bb</th>\n",
              "      <td>Cool 'n Easy Creamy Watermelon Pie</td>\n",
              "      <td>amount   unit            ingredient\n",
              "0    3....</td>\n",
              "      <td>0     Dissolve Jello in boiling water.\n",
              "1      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0000631d90</th>\n",
              "      <td>Easy Tropical Beef Skillet</td>\n",
              "      <td>amount        unit             ingredient\n",
              "0...</td>\n",
              "      <td>0    In a large skillet, toast the coconut ove...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd486a46-b9bf-45b5-b830-7cb1b000d3b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd486a46-b9bf-45b5-b830-7cb1b000d3b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd486a46-b9bf-45b5-b830-7cb1b000d3b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         title  \\\n",
              "id                                               \n",
              "000033e39b         Dilly Macaroni Salad Recipe   \n",
              "000035f7ed                            Gazpacho   \n",
              "00003a70b1           Crunchy Onion Potato Bake   \n",
              "00004320bb  Cool 'n Easy Creamy Watermelon Pie   \n",
              "0000631d90          Easy Tropical Beef Skillet   \n",
              "\n",
              "                                                  ingredients  \\\n",
              "id                                                              \n",
              "000033e39b     amount        unit       ingredient\n",
              "0    1....   \n",
              "000035f7ed     amount unit          ingredient\n",
              "0     8.0  ...   \n",
              "00003a70b1     amount   unit             ingredient\n",
              "0    2...   \n",
              "00004320bb     amount   unit            ingredient\n",
              "0    3....   \n",
              "0000631d90     amount        unit             ingredient\n",
              "0...   \n",
              "\n",
              "                                                 instructions  \n",
              "id                                                             \n",
              "000033e39b  0    Cook macaroni according to package direct...  \n",
              "000035f7ed  0    Add the tomatoes to a food processor with...  \n",
              "00003a70b1  0              Preheat oven to 350 degrees Fah...  \n",
              "00004320bb  0     Dissolve Jello in boiling water.\n",
              "1      ...  \n",
              "0000631d90  0    In a large skillet, toast the coconut ove...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 26.9 s (started: 2022-03-22 21:40:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "baseFrame = pd.DataFrame()\n",
        "\n",
        "smallSet = True\n",
        "\n",
        "if(os.path.exists(dataPath + TIMESTAMP + '/recipes_valid_full.pkl')):\n",
        "  baseFrame = pd.read_pickle(dataPath + TIMESTAMP + '/recipes_valid_full.pkl')\n",
        "elif(smallSet == True):\n",
        "  baseFrame = baseFrame.append(pd.read_pickle(glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl')[0]))\n",
        "elif(len(glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl')) != 0):\n",
        "  for file in glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl'):\n",
        "    if not 'full' in file:\n",
        "      baseFrame = baseFrame.append(pd.read_pickle(file))\n",
        "\n",
        "baseFrame.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OIncRPSKwy3r",
        "outputId": "d27df77c-6f14-4e37-baed-ae7174c26ade"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f62b36ab-4eda-4b5e-af4a-a898bdcc6bc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>instructions</th>\n",
              "      <th>amount</th>\n",
              "      <th>unit</th>\n",
              "      <th>ingredient</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000033e39b</th>\n",
              "      <td>Dilly Macaroni Salad Recipe</td>\n",
              "      <td>0    Cook macaroni according to package direct...</td>\n",
              "      <td>[1.0, 1.0, 0.5, 0.5, 3.0, 0.5, 1.0, 0.75, 0.5]</td>\n",
              "      <td>[cup, cup, cup, cup, tablespoon, cup, tablespo...</td>\n",
              "      <td>[elbow macaroni, american cheese, celery, gree...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000035f7ed</th>\n",
              "      <td>Gazpacho</td>\n",
              "      <td>0    Add the tomatoes to a food processor with...</td>\n",
              "      <td>[8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 3.0]</td>\n",
              "      <td>[, , , , , , , , ]</td>\n",
              "      <td>[tomatoes, kosher salt, red onion, green bell ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00003a70b1</th>\n",
              "      <td>Crunchy Onion Potato Bake</td>\n",
              "      <td>0              Preheat oven to 350 degrees Fah...</td>\n",
              "      <td>[2.5, 1.5, 0.25, 1.0, 8.0, 1.0, 1.0]</td>\n",
              "      <td>[, , cup, , ounce, cup, cup]</td>\n",
              "      <td>[milk, water, butter, mashed potatoes, whole k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00004320bb</th>\n",
              "      <td>Cool 'n Easy Creamy Watermelon Pie</td>\n",
              "      <td>0     Dissolve Jello in boiling water.\n",
              "1      ...</td>\n",
              "      <td>[3.0, 0.25, 12.0, 2.0, 1.0]</td>\n",
              "      <td>[ounce, cup, ounce, cup, ]</td>\n",
              "      <td>[watermelon gelatin, boiling water, cool whip,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0000631d90</th>\n",
              "      <td>Easy Tropical Beef Skillet</td>\n",
              "      <td>0    In a large skillet, toast the coconut ove...</td>\n",
              "      <td>[0.5, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 8.0, 16.0,...</td>\n",
              "      <td>[cup, pound-mass, tablespoon, , tablespoon, ta...</td>\n",
              "      <td>[shredded coconut, lean ground beef, fresh gar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f62b36ab-4eda-4b5e-af4a-a898bdcc6bc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f62b36ab-4eda-4b5e-af4a-a898bdcc6bc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f62b36ab-4eda-4b5e-af4a-a898bdcc6bc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         title  \\\n",
              "id                                               \n",
              "000033e39b         Dilly Macaroni Salad Recipe   \n",
              "000035f7ed                            Gazpacho   \n",
              "00003a70b1           Crunchy Onion Potato Bake   \n",
              "00004320bb  Cool 'n Easy Creamy Watermelon Pie   \n",
              "0000631d90          Easy Tropical Beef Skillet   \n",
              "\n",
              "                                                 instructions  \\\n",
              "id                                                              \n",
              "000033e39b  0    Cook macaroni according to package direct...   \n",
              "000035f7ed  0    Add the tomatoes to a food processor with...   \n",
              "00003a70b1  0              Preheat oven to 350 degrees Fah...   \n",
              "00004320bb  0     Dissolve Jello in boiling water.\n",
              "1      ...   \n",
              "0000631d90  0    In a large skillet, toast the coconut ove...   \n",
              "\n",
              "                                                       amount  \\\n",
              "id                                                              \n",
              "000033e39b     [1.0, 1.0, 0.5, 0.5, 3.0, 0.5, 1.0, 0.75, 0.5]   \n",
              "000035f7ed      [8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 3.0]   \n",
              "00003a70b1               [2.5, 1.5, 0.25, 1.0, 8.0, 1.0, 1.0]   \n",
              "00004320bb                        [3.0, 0.25, 12.0, 2.0, 1.0]   \n",
              "0000631d90  [0.5, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 8.0, 16.0,...   \n",
              "\n",
              "                                                         unit  \\\n",
              "id                                                              \n",
              "000033e39b  [cup, cup, cup, cup, tablespoon, cup, tablespo...   \n",
              "000035f7ed                                 [, , , , , , , , ]   \n",
              "00003a70b1                       [, , cup, , ounce, cup, cup]   \n",
              "00004320bb                         [ounce, cup, ounce, cup, ]   \n",
              "0000631d90  [cup, pound-mass, tablespoon, , tablespoon, ta...   \n",
              "\n",
              "                                                   ingredient  \n",
              "id                                                             \n",
              "000033e39b  [elbow macaroni, american cheese, celery, gree...  \n",
              "000035f7ed  [tomatoes, kosher salt, red onion, green bell ...  \n",
              "00003a70b1  [milk, water, butter, mashed potatoes, whole k...  \n",
              "00004320bb  [watermelon gelatin, boiling water, cool whip,...  \n",
              "0000631d90  [shredded coconut, lean ground beef, fresh gar...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 22.2 s (started: 2022-03-22 21:40:35 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def getAmount(row):\n",
        "  return row['amount'].tolist()\n",
        "def getUnit(row):\n",
        "  return row['unit'].tolist()\n",
        "def getIng(row):\n",
        "  return row['ingredient'].tolist()\n",
        "\n",
        "baseFrame['amount'] = np.vectorize(getAmount, otypes=[np.ndarray])(baseFrame['ingredients'])\n",
        "baseFrame['unit'] = np.vectorize(getUnit, otypes=[np.ndarray])(baseFrame['ingredients'])\n",
        "baseFrame['ingredient'] = np.vectorize(getIng, otypes=[np.ndarray])(baseFrame['ingredients'])\n",
        "baseFrame = baseFrame.drop(columns=['ingredients'])\n",
        "baseFrame.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf20_SrBw-i-"
      },
      "source": [
        "## Imports for Learning\n",
        "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5pwzWep0k_99",
        "outputId": "6b4ced3b-9595-4178-f8b6-bb941cea90e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 6.99 s (started: 2022-03-22 21:40:57 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable \n",
        "from torchsummary import summary\n",
        "\n",
        "# Optimizer\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# Tokenizer\n",
        "# torch padding does only support constant padding (ConstantPad1d) for 1D or non-constant padding for >1D (nn.function.pad)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# keras tokenizer more powerful than torch\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from torchtext.data import get_tokenizer # https://pytorch.org/text/stable/data_utils.html\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "# hyperparameter tuning\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pOeZxpgBOaY"
      },
      "source": [
        "# Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jjrp4aPbBL-r",
        "outputId": "c361fcd4-1ef4-4ec0-81c1-a410658cc68f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc0b82629b0>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 3.41 ms (started: 2022-03-22 21:41:04 +00:00)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIhRxE1cj5ps"
      },
      "source": [
        "# Setup\n",
        "https://closeheat.com/blog/pytorch-lstm-text-generation-tutorial\n",
        "\n",
        "\n",
        "## Tokenization\n",
        "to be checked: necessity of punctuation (maybe reintroduce later: https://stackoverflow.com/questions/49073673/include-punctuation-in-keras-tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5XkLuiCIbKS"
      },
      "source": [
        "### Get Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jER6BpRl8ikx",
        "outputId": "c6e6ca54-e388-4335-f5fb-dfe8fbfebf62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab.bin not to be used as dict misses words\n",
            "time: 1.43 s (started: 2022-03-22 21:41:04 +00:00)\n"
          ]
        }
      ],
      "source": [
        "w2v_model = word2vec.load(dataPath + 'vocab.bin')\n",
        "ingredientDict = {}\n",
        "for voc in w2v_model.vocab:\n",
        "     # Offset by 1 so empty fields can be 0\n",
        "     ingredientDict.setdefault(voc, len(ingredientDict)+1)\n",
        "\n",
        "if 'dilly' in ingredientDict:\n",
        "  print(\"Word exists\")\n",
        "else:\n",
        "  print('vocab.bin not to be used as dict misses words') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TyxLsHZmQ0_o",
        "outputId": "6b9f17e0-ae14-4a2f-cba3-dfecb0758551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 6.84 s (started: 2022-03-22 21:41:05 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def getCorpus(title, ingredient, instructions):\n",
        "  titleTok = text_to_word_sequence(title)\n",
        "  ingTok = text_to_word_sequence(' '.join(ingredient))\n",
        "  instTok = text_to_word_sequence(' '.join(instructions))\n",
        "  return np.array(ingTok + titleTok + instTok)\n",
        "\n",
        "corpus = np.vectorize(getCorpus, otypes=[np.ndarray])(baseFrame['title'], baseFrame['ingredient'], baseFrame['instructions'])\n",
        "corpus = np.concatenate(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tmFQxxDKSW9"
      },
      "source": [
        "###  Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9VbmOw8mDyOP",
        "outputId": "3b4ee414-07b7-4c87-e2fe-5041b3135d4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ings': ['elbow',\n",
              "  'macaroni',\n",
              "  'american',\n",
              "  'cheese',\n",
              "  'celery',\n",
              "  'green',\n",
              "  'peppers',\n",
              "  'pimentos',\n",
              "  'mayonnaise',\n",
              "  'vinegar',\n",
              "  'salt',\n",
              "  'dry',\n",
              "  'dill',\n",
              "  'weed'],\n",
              " 'title': ['dilly', 'macaroni', 'salad', 'recipe']}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 6.75 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "test = baseFrame.head(20).copy()\n",
        "\n",
        "def getTitleSequence(title, ingredient):\n",
        "  titleTok = text_to_word_sequence(title)\n",
        "  ingTok = text_to_word_sequence(' '.join(ingredient))\n",
        "  return {'ings': ingTok, 'title': titleTok}\n",
        "\n",
        "titleSeq = np.vectorize(getTitleSequence, otypes=[np.ndarray])(test['title'], test['ingredient'])\n",
        "titleSeq[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rbb9g8Xkex5A",
        "outputId": "4bdf0afd-be8f-4a73-f777-55810c59ee70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['elbow', 'macaroni', 'american', 'cheese', 'celery', 'green',\n",
              "        'peppers', 'pimentos', 'mayonnaise', 'vinegar', 'salt', 'dry',\n",
              "        'dill', 'weed'], dtype='<U32'),\n",
              " array(['macaroni', 'american', 'cheese', 'celery', 'green', 'peppers',\n",
              "        'pimentos', 'mayonnaise', 'vinegar', 'salt', 'dry', 'dill', 'weed',\n",
              "        'dilly'], dtype='<U32'))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 9.57 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def getNGramSeq(seq):\n",
        "  # input needs to be pre padded\n",
        "  idxShift = len(seq['title'])\n",
        "  ingLen = len(seq['ings'])\n",
        "  fullSeq = np.array(seq['ings'] + seq['title'])\n",
        "  retSeq = np.empty((0,ingLen + 1))\n",
        "  for i_shift in range(idxShift):\n",
        "    retSeq = np.vstack([retSeq, np.array(fullSeq[i_shift:ingLen+i_shift+1])])\n",
        "  return retSeq\n",
        "\n",
        "ngramSeq = pd.Series(np.vectorize(getNGramSeq, otypes=[np.ndarray])(titleSeq)).explode().to_numpy()\n",
        "ngramSeq[0][:-1], ngramSeq[0][1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTSZL7Xka-qr"
      },
      "source": [
        "### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SGKlvcMia9Ts",
        "outputId": "c195163f-d2e3-4982-afe8-c54658ee2fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 6.61 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class HyperParams():\n",
        "  def __init__(self, epochs=10, batchSize=10, lr=1e-3, ratio=[0.7, 0.2, 0.1]):\n",
        "    self.epochs = epochs\n",
        "    self.batchSize = batchSize\n",
        "    self.lr = lr\n",
        "    self.ratio = ratio\n",
        "\n",
        "    self.hidden_dim = 256 #number of features in hidden state\n",
        "    self.num_layers = 1 #number of stacked lstm layers\n",
        "    self.embedding_dim = 200 # embedding dimension\n",
        "\n",
        "  def __str__(self):\n",
        "    return('epochs ' + str(self.epochs) + '\\n' +\n",
        "    'batchSize ' + str(self.batchSize) + '\\n' +\n",
        "    'lr ' + str(self.lr) + '\\n' +\n",
        "    'ratio train|val|test' + str(self.ratio) + '\\n' +\n",
        "    # 'input_size ' + str(self.input_size) + '\\n' +\n",
        "    'hidden_dim ' + str(self.hidden_dim) + '\\n' +\n",
        "    'num_layers ' + str(self.num_layers) + '\\n' +\n",
        "    # 'num_classes ' + str(self.num_classes) + '\\n' +\n",
        "    'embedding_dim ' + str(self.embedding_dim) + '\\n')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcnDjUaHKVHn"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eRKA1xo1thoy",
        "outputId": "3ab23228-510d-4742-e83b-3d20110ea342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 51.3 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class InstructionSet(Dataset):\n",
        "    def __init__(self, hyperparams, data):\n",
        "      self.hyperparams = hyperparams\n",
        "\n",
        "      to_exclude = '\\n'\n",
        "      self.tokenizer = Tokenizer(filters=to_exclude)\n",
        "\n",
        "      # dataset split into word sequences required for training\n",
        "      self.wordSeq = np.vectorize(self.getSequence, otypes=[np.ndarray])(data['ingredient'], data['title'],  data['instructions'])\n",
        "\n",
        "      # training requires same length sequences -->  padding\n",
        "      self.maxSequenceLength = max([len(seq['ingTitle']) for seq in self.wordSeq])\n",
        "\n",
        "      # list of all words in dataset\n",
        "      self.words = np.concatenate(np.vectorize(self.getCorpus, otypes=[np.ndarray])(data['ingredient'], data['title'], data['instructions']))\n",
        "\n",
        "      # tokenization corpus\n",
        "      self.tokenizer.fit_on_texts(self.words)\n",
        "\n",
        "      # indexed wordSequences (could be calculated in getter but very slow, preprocessing better)\n",
        "      self.idxWords = np.vectorize(self.getIndexedSeqs, otypes=[np.ndarray])(self.wordSeq)\n",
        "\n",
        "      # n gram sequences\n",
        "      self.movWindSeq = pd.Series(np.vectorize(self.getMovWindSeq, otypes=[np.ndarray])(self.idxWords)).explode()\n",
        "      self.movWindSeq.dropna(inplace=True)\n",
        "      self.movWindSeq = self.movWindSeq.to_numpy()\n",
        "\n",
        "\n",
        "    def getCorpus(self, ingredient, title, instructions):\n",
        "      ingTok = text_to_word_sequence(' '.join(ingredient))\n",
        "      titleTok = text_to_word_sequence(title)\n",
        "      instTok = text_to_word_sequence(' \\n '.join(instructions))\n",
        "      return np.array(ingTok + titleTok + instTok)\n",
        "\n",
        "    def getSequence(self, ingredient, title, instructions):\n",
        "      ingTok = text_to_word_sequence(' '.join(ingredient))\n",
        "      titleTok = text_to_word_sequence(title)\n",
        "      instTok = text_to_word_sequence(' \\n '.join(instructions))\n",
        "      return {'ingTitle': ingTok + titleTok, 'instructions': instTok}\n",
        "\n",
        "    def getIndexedSeqs(self, seq):\n",
        "      ingTok = self.tokenizer.texts_to_sequences([seq['ingTitle']])[0]\n",
        "      ingTok = pad_sequences([ingTok], maxlen=self.maxSequenceLength, padding='pre')[0] # https://arxiv.org/abs/1903.07288\n",
        "      instTok = self.tokenizer.texts_to_sequences([seq['instructions']])[0]\n",
        "\n",
        "      return {'ingTitle': ingTok, 'instructions': instTok}\n",
        "\n",
        "    def getNGramSeq(self, seq):\n",
        "      # input needs to be pre padded\n",
        "      idxShift = len(seq['instructions'])\n",
        "      ingLen = len(seq['ingTitle'])\n",
        "\n",
        "      fullSeq = np.append(seq['ingTitle'], seq['instructions'])\n",
        "      retSeq = np.empty((0,ingLen + 1), dtype=np.int32)\n",
        "\n",
        "      for i_shift in range(idxShift):\n",
        "        retSeq = np.vstack([retSeq, np.array(fullSeq[i_shift:ingLen+i_shift+1])])\n",
        "      return retSeq\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxWords)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.ngramSeq[index][:-1]),\n",
        "            torch.tensor(self.ngramSeq[index][1:])\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gukTWG9C5kAR"
      },
      "source": [
        "## Model\n",
        "LSTM Net: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "\n",
        "Embedding Net: https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
        "\n",
        "Init state: https://stats.stackexchange.com/questions/224737/best-way-to-initialize-lstm-state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtJQI0JktCJe"
      },
      "source": [
        "<!-- ### base: https://github.com/yuchenlin/lstm_sentence_classifier/blob/master/LSTM_sentence_classifier.py -->\n",
        "\n",
        "### base: https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdhkbXIio_f3"
      },
      "source": [
        "### base: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#lstms-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aivLE2pzGHlk",
        "outputId": "7dec0557-59ff-41bb-cc97-54c9c4a19759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 20.9 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Model2(nn.Module):\n",
        "\n",
        "    def __init__(self, hyperParams, dataset, device):\n",
        "        super(Model3, self).__init__()\n",
        "\n",
        "        # initialize vital params\n",
        "        self.vocab_size = len(dataset.tokenizer.word_index)\n",
        "        self.batchSize = hyperParams.batchSize\n",
        "        self.hidden_size = hyperParams.hidden_dim\n",
        "        self.device = device\n",
        "        self.num_layers = hyperParams.num_layers\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(self.vocab_size, hyperParams.embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(input_size=hyperParams.embedding_dim, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        embeds = self.word_embeddings(x)\n",
        "\n",
        "        lstm_out, (hidden, cell) = self.lstm(embeds, (hidden.detach(), cell.detach()))\n",
        "\n",
        "        out = self.linear(lstm_out.reshape(-1, self.hidden_size))\n",
        "\n",
        "        return out, (hidden, cell)\n",
        "\n",
        "    # def init_hidden(self, batchSize=None):\n",
        "    #     ''' initializes hidden state '''\n",
        "    #     # Create two new tensors with sizes num_layers x batchSize x hidden_dim,\n",
        "    #     # initialized to zero, for hidden state and cell state of LSTM\n",
        "    #     weight = next(self.parameters()).data\n",
        "\n",
        "    #     batchSize = self.batchSize if batchSize == None else batchSize\n",
        "\n",
        "    #     hidden = (weight.new(self.num_layers, batchSize, self.hidden_dim).zero_().to(self.device),\n",
        "    #               weight.new(self.num_layers, batchSize, self.hidden_dim).zero_().to(self.device))\n",
        "        \n",
        "    #     return hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6XByY-PwpBlI",
        "outputId": "e96d98b2-9578-4eca-8ae8-e8de13b62e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 20.7 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Model3(nn.Module):\n",
        "\n",
        "    def __init__(self, hyperParams, dataset, device):\n",
        "        super(Model3, self).__init__()\n",
        "\n",
        "        # initialize vital params\n",
        "        self.vocab_size = len(dataset.tokenizer.word_index)\n",
        "        self.batchSize = hyperParams.batchSize\n",
        "        self.hidden_size = hyperParams.hidden_dim\n",
        "        self.device = device\n",
        "        self.num_layers = hyperParams.num_layers\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(self.vocab_size, hyperParams.embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(input_size=hyperParams.embedding_dim, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        embeds = self.word_embeddings(x)\n",
        "\n",
        "        lstm_out, (hidden, cell) = self.lstm(embeds, (hidden.detach(), cell.detach()))\n",
        "\n",
        "        out = self.linear(lstm_out.reshape(-1, self.hidden_size))\n",
        "\n",
        "        return out, (hidden, cell)\n",
        "\n",
        "    # def init_hidden(self, batchSize=None):\n",
        "    #     ''' initializes hidden state '''\n",
        "    #     # Create two new tensors with sizes num_layers x batchSize x hidden_dim,\n",
        "    #     # initialized to zero, for hidden state and cell state of LSTM\n",
        "    #     weight = next(self.parameters()).data\n",
        "\n",
        "    #     batchSize = self.batchSize if batchSize == None else batchSize\n",
        "\n",
        "    #     hidden = (weight.new(self.num_layers, batchSize, self.hidden_dim).zero_().to(self.device),\n",
        "    #               weight.new(self.num_layers, batchSize, self.hidden_dim).zero_().to(self.device))\n",
        "        \n",
        "    #     return hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyuY9T8a5pqr"
      },
      "source": [
        "## Training\n",
        "mixture of \n",
        "* https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
        "* https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
        "* https://stackoverflow.com/questions/67295494/correct-validation-loss-in-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hbilmeqIMagF",
        "outputId": "ad1668ca-8d9b-4846-9144-3bcf0a37ce51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 18.6 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def train_epoch(epoch, batchSize, model, criterion, optimizer, train_loader, device, writer):\n",
        "  running_loss = 0.\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  h,c = model.init_hidden(batchSize)\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch, (inputs, labels) in enumerate(train_loader):\n",
        "    if epoch == 0 and batch == 0:\n",
        "      writer.add_graph(model, input_to_model=(inputs.to(device), h, c), verbose=False)\n",
        "\n",
        "    # assign inputs and labels to device\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    # detach hidden states\n",
        "    # h = tuple([each.data for each in h])\n",
        "\n",
        "    # clear gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # batch prediction\n",
        "    outputs, (h,c) = model(inputs, h, c)\n",
        "    labels = labels.long()\n",
        "\n",
        "    # loss computation\n",
        "    loss = criterion(outputs, labels.view(-1))\n",
        "\n",
        "    # calc backward gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # run optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    # _, predicted = outputs.max(1)\n",
        "    # print(outputs.shape)\n",
        "    # print(predicted.shape)\n",
        "    # total += labels.size(0)\n",
        "    # correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "  print(\"Epoch: %d, loss: %1.5f\" % (epoch+1, running_loss / len(train_loader)))\n",
        "  return( running_loss / len(train_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nzJxiyTtNdXR",
        "outputId": "ad31e6c6-3d4e-46e0-840e-c0a9b6c1d3a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 11 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def val_epoch(epoch, batchSize, model, criterion, optimizer, val_loader, device, writer):\n",
        "  # Validation Loss\n",
        "  correct = 0                                               \n",
        "  total = 0                                                 \n",
        "  running_loss = 0.0    \n",
        "\n",
        "  h,c = model.init_hidden(batchSize)\n",
        "      \n",
        "  model.eval() # what does it do\n",
        "  with torch.no_grad(): # what does it do\n",
        "    for batch, (inputs, labels) in enumerate(val_loader):\n",
        "      # assign inputs and labels to device\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # batch prediction (alternative: forward)\n",
        "      outputs, (h,c) = model(inputs, h, c)\n",
        "      labels = labels.long()\n",
        "\n",
        "      # loss computation\n",
        "      loss = criterion(outputs, labels.view(-1))\n",
        "\n",
        "      # _, predicted = torch.max(outputs.data, 1)\n",
        "      # total += labels.size(0)\n",
        "      # correct += (predicted == labels).sum().item()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "  # # mean_val_accuracy = (100 * correct / total)               \n",
        "  mean_val_loss = ( running_loss )   \n",
        "  # # print('Validation Accuracy: %d %%' % (mean_val_accuracy)) \n",
        "  # print('Validation Loss:'  ,mean_val_loss )\n",
        "  return( running_loss / len(val_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U258NxuRDRRx",
        "outputId": "6ad0888b-f4c8-444f-be57-17def7791ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 11.2 ms (started: 2022-03-22 21:41:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def train(dataset, model, hyperparams, device):\n",
        "  timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "  trainWriter = SummaryWriter('/content/drive/MyDrive/runs/instTrainer/train'.format(timestamp))\n",
        "  valWriter = SummaryWriter('/content/drive/MyDrive/runs/instTrainer/validation'.format(timestamp))\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
        "\n",
        "  # split data\n",
        "  train_set, val_set = dataset['train'], dataset['val']\n",
        "  \n",
        "  train_loader = DataLoader(train_set, batch_size=hyperparams.batchSize, drop_last=True)\n",
        "  val_loader   = DataLoader(val_set, batch_size=hyperparams.batchSize, drop_last=True)\n",
        "  # further options: shuffle, num_workers\n",
        "\n",
        "  for epoch in range(hyperparams.epochs):\n",
        "    trainLoss = train_epoch(epoch, hyperparams.batchSize, model, criterion, optimizer, train_loader, device, trainWriter)\n",
        "    valLoss = val_epoch(epoch, hyperparams.batchSize, model, criterion, optimizer, val_loader, device, valWriter)\n",
        "\n",
        "    trainWriter.add_scalar('loss', trainLoss, epoch)  \n",
        "    valWriter.add_scalar('loss', valLoss, epoch)  \n",
        "    \n",
        "  trainWriter.flush()\n",
        "  valWriter.flush()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ov7EPe_eqmbP",
        "outputId": "e58b1216-8edb-445d-fce7-89f961fa0e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 13.8 ms (started: 2022-03-22 21:41:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def predict(model, dataset, tkn, h, c):\n",
        "         \n",
        "  # tensor inputs\n",
        "  x = np.array([[dataset.tokenizer.word_index[tkn]]])\n",
        "  inputs = torch.from_numpy(x)\n",
        "  print('inp')\n",
        "  print(inputs.shape)\n",
        "  \n",
        "  # push to GPU\n",
        "  inputs = inputs.to(device)\n",
        "\n",
        "  # get the output of the model\n",
        "  out, (h, c) = model(inputs, h, c)\n",
        "\n",
        "  # get the token probabilities\n",
        "  print('out')\n",
        "  print(out.shape)\n",
        "  p = F.softmax(out, dim=1).data\n",
        "  print('pred')\n",
        "  print(p.shape)\n",
        "  print(p.reshape(p.shape[1],).shape)\n",
        "\n",
        "  p = p.cpu()\n",
        "  p = p.numpy()\n",
        "  p = p.reshape(p.shape[1],)\n",
        "\n",
        "  # get indices of top 3 values\n",
        "  print(np.argmax(p))\n",
        "  top_n_idx = p.argsort()[-3:][::-1]\n",
        "\n",
        "  # randomly select one of the three indices\n",
        "  sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
        "\n",
        "  # return the encoded value of the predicted char and the hidden state\n",
        "  return sampled_token_index, (h, c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "64k_4kiFFwec",
        "outputId": "71975466-f5d4-4d9f-d6f1-59db9bc88f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 12.4 ms (started: 2022-03-22 21:41:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# function to generate text\n",
        "def sample(model, dataset, size, device, initial):\n",
        "        \n",
        "    # push to GPU\n",
        "    model.to(device)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    # batch size is 1\n",
        "    h, c = model.init_hidden(1)\n",
        "\n",
        "    toks = initial\n",
        "    title = []\n",
        "\n",
        "    # predict next token\n",
        "    for t in initial:\n",
        "      token_idx, (h, c) = predict(model, dataset, t, h, c)\n",
        "    \n",
        "    if token_idx > 0:\n",
        "      token = dataset.tokenizer.index_word[token_idx]\n",
        "      toks.append(token)\n",
        "    else:\n",
        "      token = ';'\n",
        "    \n",
        "    title.append(token)\n",
        "\n",
        "    # predict subsequent tokens\n",
        "    for i in range(size-1):\n",
        "        token_idx, (h, c) = predict(model, dataset, toks[-1], h, c)\n",
        "        if token_idx > 0:\n",
        "          token = dataset.tokenizer.index_word[token_idx]\n",
        "          toks.append(token)\n",
        "        else:\n",
        "          token = ';'\n",
        "        title.append(token)\n",
        "\n",
        "    return ' '.join(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdDLkBBLbNiz"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dHdjyULcN1d1",
        "outputId": "c78e20ff-a87a-4e3c-c634-849b91843d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs 50\n",
            "batchSize 32\n",
            "lr 0.001\n",
            "ratio train|val|test[0.7, 0.2, 0.1]\n",
            "hidden_dim 256\n",
            "num_layers 1\n",
            "embedding_dim 200\n",
            "\n",
            "time: 1.36 ms (started: 2022-03-22 21:41:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "hyperParams = HyperParams(epochs=50, batchSize=32)\n",
        "print(hyperParams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xWe4t2xp_Ieg",
        "outputId": "69a2a511-b47d-491b-81ab-bc134a039057"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-64292b5bb499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minstSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstructionSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msplitSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msplitSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplitSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplitSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplitSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-40a3d47076c9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hyperparams, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m# n gram sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovWindSeq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMovWindSeq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovWindSeq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovWindSeq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovWindSeq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attribute_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1min 2s (started: 2022-03-22 21:41:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "instSet = InstructionSet(hyperParams, baseFrame)\n",
        "splitSet = random_split(instSet, [int(hyperParams.ratio[0] * len(instSet)), int(hyperParams.ratio[1] * len(instSet)), int(hyperParams.ratio[2] * len(instSet))], generator=torch.Generator().manual_seed(0))\n",
        "splitSet = {'train': splitSet[0], 'val': splitSet[1], 'test': splitSet[2]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7cAHwy4Y13_r"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oOYpjAPHE3HY"
      },
      "outputs": [],
      "source": [
        "model = Model3(hyperParams, instSet, device)\n",
        "model.to(device)\n",
        "print(model)\n",
        "# summary(model, (16,53))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CL4vqYn0aXXk",
        "outputId": "b0cf007d-3585-464d-9ebe-c3f91225a90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 3.47934\n",
            "Epoch: 2, loss: 2.30626\n",
            "Epoch: 3, loss: 1.85036\n",
            "Epoch: 4, loss: 1.61080\n",
            "Epoch: 5, loss: 1.46837\n",
            "Epoch: 6, loss: 1.37494\n",
            "Epoch: 7, loss: 1.31024\n",
            "Epoch: 8, loss: 1.26205\n",
            "Epoch: 9, loss: 1.22551\n",
            "Epoch: 10, loss: 1.19719\n",
            "Epoch: 11, loss: 1.17344\n",
            "Epoch: 12, loss: 1.15464\n",
            "Epoch: 13, loss: 1.13828\n",
            "Epoch: 14, loss: 1.12577\n",
            "Epoch: 15, loss: 1.11415\n",
            "Epoch: 16, loss: 1.10420\n",
            "Epoch: 17, loss: 1.09501\n",
            "Epoch: 18, loss: 1.08751\n",
            "Epoch: 19, loss: 1.07986\n",
            "Epoch: 20, loss: 1.07383\n",
            "Epoch: 21, loss: 1.06840\n",
            "Epoch: 22, loss: 1.06360\n",
            "Epoch: 23, loss: 1.05879\n",
            "Epoch: 24, loss: 1.05476\n",
            "Epoch: 25, loss: 1.05162\n",
            "Epoch: 26, loss: 1.04824\n",
            "Epoch: 27, loss: 1.04435\n",
            "Epoch: 28, loss: 1.04166\n",
            "Epoch: 29, loss: 1.03866\n",
            "Epoch: 30, loss: 1.03588\n",
            "Epoch: 31, loss: 1.03428\n",
            "Epoch: 32, loss: 1.03249\n",
            "Epoch: 33, loss: 1.03064\n",
            "Epoch: 34, loss: 1.02836\n",
            "Epoch: 35, loss: 1.02763\n",
            "Epoch: 36, loss: 1.02467\n",
            "Epoch: 37, loss: 1.02484\n",
            "Epoch: 38, loss: 1.02381\n",
            "Epoch: 39, loss: 1.02162\n",
            "Epoch: 40, loss: 1.02058\n",
            "Epoch: 41, loss: 1.01916\n",
            "Epoch: 42, loss: 1.01842\n",
            "Epoch: 43, loss: 1.01854\n",
            "Epoch: 44, loss: 1.01680\n",
            "Epoch: 45, loss: 1.01644\n",
            "Epoch: 46, loss: 1.01640\n",
            "Epoch: 47, loss: 1.01658\n",
            "Epoch: 48, loss: 1.01569\n",
            "Epoch: 49, loss: 1.01801\n",
            "Epoch: 50, loss: 1.01567\n",
            "time: 2h 1min 57s (started: 2022-03-25 00:09:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train(splitSet, model, hyperParams, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "foZTcBSWXDGp",
        "outputId": "c5ee5e74-792e-439b-a60a-3bf37b5843ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['olive', 'oil', 'onions', 'pepper', 'courgettes', 'aubergines', 'cherry', 'tomatoes', 'pasta', 'sauce', \"goat's\", 'cheese', 'basil', 'leaves', 'pasta', 'bake', 'with', \"goats'\", 'cheese']\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'melt the butter over a medium heat to medium and simmer over medium heat without stirring once mixture has softened add pepper and shrimp to brown stir for about 5 7 to 4 minutes drain and rinse the lentils with cold water in small bowl stir the mayonnaise lemon zest oregano and salt bring back into the sauce add salt water and to simmer gently stirring until thickened stirring constantly until the sugar melts stir in all purpose orange rind orange sugar salt heat oven 1 1 2 1 4 cup unsweetened chocolate sugar orange juice orange juice lemon juice and sugar beat in eggs one tablespoon of butter over each side using the bottom add your fingers or the top of each pan and add it into a spoon to extract the custard so to add the potatoes to make the bowl and add a small pot over the skillet then add the chicken and cook until it begins to boil pour this mixture over the crust and then place the whole in baking pan place the potatoes and tomatoes on top of the meat with some of it place in a shallow pan on the stove add about 2 cups sugar cinnamon and ginger in the microwave or until it is emulsified whisk in sugar until the flour dissolves then stir together flour sugar 1 4 teaspoon cinnamon gradually beat until smooth and add egg beat till shiny peaks add egg whites beat until combined and vanilla add flour and eggs and beat until well combined stir in the milk salt and sugar then mix in eggs and sugar add all at the oats fiber one or two granulated sugar and 1 4 cup sugar until well blended add remaining flour until incorporated into a ball place the'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.96 s (started: 2022-03-25 02:10:59 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# sample(model, titleSet, 6, device, initial=['dry', 'penne', 'pasta', 'broccoli', 'sun', 'dried', 'tomatoes', 'packed', 'in', 'oil', 'garlic', 'cloves', 'cheddar', 'cheese', 'salt', 'black', 'pepper'])\n",
        "seq = splitSet['test'][np.random.randint(0, len(splitSet['test']))][0].tolist()\n",
        "\n",
        "def remove_values_from_list(the_list, val):\n",
        "   return [instSet.t300kenizer.index_word[value] for value in the_list if value != val]\n",
        "\n",
        "seq = remove_values_from_list(seq, 0)\n",
        "print(seq)\n",
        "\n",
        "sample(model, instSet, 300, device, initial=seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4Ot4C2SSfFOT",
        "outputId": "68029b52-49b3-47b0-f03d-9ae462186e5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b697c2c6-feac-4373-81ab-f7a6d5faa034\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kaga</th>\n",
              "      <td>62904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thn</th>\n",
              "      <td>62905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gym</th>\n",
              "      <td>62906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>uncontaminated</th>\n",
              "      <td>62907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pastilla</th>\n",
              "      <td>62908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62908 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b697c2c6-feac-4373-81ab-f7a6d5faa034')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b697c2c6-feac-4373-81ab-f7a6d5faa034 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b697c2c6-feac-4373-81ab-f7a6d5faa034');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                    0\n",
              "the                 1\n",
              "and                 2\n",
              "a                   3\n",
              "in                  4\n",
              "to                  5\n",
              "...               ...\n",
              "kaga            62904\n",
              "thn             62905\n",
              "gym             62906\n",
              "uncontaminated  62907\n",
              "pastilla        62908\n",
              "\n",
              "[62908 rows x 1 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 27.6 ms (started: 2022-03-25 02:11:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "pd.DataFrame.from_dict(pd.Series(instSet.tokenizer.word_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG3G4d4KYlxj"
      },
      "source": [
        "# Tensorboard visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NgcJKS4lfsY0",
        "outputId": "8b1fae5d-d406-45af-9c9b-e8de01116936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 1117), started 2:20:56 ago. (Use '!kill 1117' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 9.8 ms (started: 2022-03-25 02:11:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=/content/drive/MyDrive/runs/instTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DhDetWcvllGW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPSgLtn3eqTae4YUZKrpVBR",
      "background_execution": "on",
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "instrGen.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3fdf690c1af034860327f6e88593679f4c8f379dfd49f26501dd3437e25c11ad"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python385jvsc74a57bd03fdf690c1af034860327f6e88593679f4c8f379dfd49f26501dd3437e25c11ad"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
