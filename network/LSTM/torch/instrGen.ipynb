{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mscholl96/mad-recime/blob/network_LSTM/network/LSTM/instrGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Instruction Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R3yLJ1_xBA2"
      },
      "source": [
        "## Basic includes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XN0Eb2xPKgV",
        "outputId": "e2248dec-5930-4cc3-aa93-dc2f184e9c45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 0 ns (started: 2022-04-04 22:31:31 +02:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime --quiet\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect colab and set paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06MHgolQxDOM",
        "outputId": "78e0000d-a14d-4715-87f1-92a57bb34e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 16 ms (started: 2022-04-04 22:31:31 +02:00)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "except:\n",
        "    # local exec\n",
        "    dataPath = os.path.join(os.getcwd(), '../../../data/2022_03_19')\n",
        "    logDir = os.path.join(os.getcwd(), 'logs/instruction/')\n",
        "    saveDir = os.path.join(os.getcwd(), 'model/instruction/')\n",
        "\n",
        "    sys.path.append(os.getcwd())\n",
        "else: \n",
        "    rootDir = '/content/drive/MyDrive/'\n",
        "\n",
        "    TIMESTAMP = '2022_03_30'\n",
        "\n",
        "    dataPath = rootDir + 'Colab Notebooks/recime/data/' + TIMESTAMP\n",
        "    logDir = rootDir + 'Colab Notebooks/recime/LSTM/torch/logs/instruction/'\n",
        "    saveDir = rootDir + 'Colab Notebooks/recime/LSTM/torch/model/instruction/'\n",
        "\n",
        "    sys.path.append(rootDir + 'Colab Notebooks/recime/LSTM/torch')\n",
        "\n",
        "if not os.path.exists(logDir):\n",
        "  os.makedirs(logDir)\n",
        "if not os.path.exists(saveDir):\n",
        "  os.makedirs(saveDir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf20_SrBw-i-"
      },
      "source": [
        "## Basic includes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5pwzWep0k_99",
        "outputId": "6b4ced3b-9595-4178-f8b6-bb941cea90e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 4.47 s (started: 2022-04-04 22:31:32 +02:00)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import importlib\n",
        "\n",
        "import pickle\n",
        "import yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 12.3 s (started: 2022-04-04 22:31:36 +02:00)\n"
          ]
        }
      ],
      "source": [
        "import src.data as dataLib\n",
        "import src.models as modelLib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pOeZxpgBOaY"
      },
      "source": [
        "## Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jjrp4aPbBL-r",
        "outputId": "c361fcd4-1ef4-4ec0-81c1-a410658cc68f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 16 ms (started: 2022-04-04 22:31:49 +02:00)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7cAHwy4Y13_r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 0 ns (started: 2022-04-04 22:31:49 +02:00)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device == \"cuda\":\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdDLkBBLbNiz"
      },
      "source": [
        "### Set hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dHdjyULcN1d1",
        "outputId": "c78e20ff-a87a-4e3c-c634-849b91843d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs 1\n",
            "batchSize 2\n",
            "lr 0.001\n",
            "ratio train|val [0.7, 0.3]\n",
            "hiddenDim 10\n",
            "numLayers 1\n",
            "embeddingDim 100\n",
            "\n",
            "time: 16 ms (started: 2022-04-04 22:31:49 +02:00)\n"
          ]
        }
      ],
      "source": [
        "importlib.reload(modelLib)\n",
        "\n",
        "hp = modelLib.HyperParams(epochs=1, batchSize=2, hiddenDim=10, numLayers=1, embeddingDim=100) # just for local test\n",
        "# hp = modelLib.HyperParams(epochs=30, batchSize=32, hiddenDim=256, numLayers=1, embeddingDim=300)\n",
        "print(hp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xWe4t2xp_Ieg",
        "outputId": "69a2a511-b47d-491b-81ab-bc134a039057"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\02_Studium\\SBX\\mad-recime\\network\\LSTM\\torch\\src\\data.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  baseFrame = baseFrame.append(pd.read_pickle(dataSetSplits[split]))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 4.22 s (started: 2022-04-04 22:31:50 +02:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\02_Studium\\SBX\\mad-recime\\network\\LSTM\\torch\\src\\data.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  baseFrame = baseFrame.append(pd.read_pickle(dataSetSplits[split]))\n"
          ]
        }
      ],
      "source": [
        "importlib.reload(dataLib)\n",
        "\n",
        "instSet = dataLib.InstructionSet(dataPath, setSize=2)\n",
        "\n",
        "testSet = dataLib.getPreProcData(dataPath, range(-1,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>deg</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>drying</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shut</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cavity</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moisten</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\n</th>\n",
              "      <td>888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1665 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "deg        1\n",
              "drying     1\n",
              "shut       1\n",
              "cavity     1\n",
              "moisten    1\n",
              "...      ...\n",
              "a        269\n",
              "in       303\n",
              "and      556\n",
              "the      570\n",
              "\\n       888\n",
              "\n",
              "[1665 rows x 1 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 47 ms (started: 2022-04-04 22:31:54 +02:00)\n"
          ]
        }
      ],
      "source": [
        "wordCount = pd.DataFrame.from_dict(pd.Series(instSet.tokenizer.word_counts).sort_values())\n",
        "wordCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>OOV</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\n</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>verde</th>\n",
              "      <td>1662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>curd</th>\n",
              "      <td>1663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dj's</th>\n",
              "      <td>1664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dishes</th>\n",
              "      <td>1665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deg</th>\n",
              "      <td>1666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1666 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "OOV        1\n",
              "\\n         2\n",
              "the        3\n",
              "and        4\n",
              "in         5\n",
              "...      ...\n",
              "verde   1662\n",
              "curd    1663\n",
              "dj's    1664\n",
              "dishes  1665\n",
              "deg     1666\n",
              "\n",
              "[1666 rows x 1 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 15 ms (started: 2022-04-04 22:31:55 +02:00)\n"
          ]
        }
      ],
      "source": [
        "pd.DataFrame.from_dict(pd.Series(instSet.tokenizer.word_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oOYpjAPHE3HY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EmbedLSTM(\n",
            "  (word_embeddings): Embedding(1666, 100, padding_idx=0)\n",
            "  (lstm): LSTM(100, 10, batch_first=True)\n",
            "  (linear): Linear(in_features=10, out_features=1666, bias=True)\n",
            ")\n",
            "time: 31 ms (started: 2022-04-04 22:31:55 +02:00)\n"
          ]
        }
      ],
      "source": [
        "importlib.reload(modelLib)\n",
        "\n",
        "model = modelLib.EmbedLSTM(hp, instSet.tokenizer, device)\n",
        "model.to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CL4vqYn0aXXk",
        "outputId": "b0cf007d-3585-464d-9ebe-c3f91225a90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss:    7.31105, acc:    0.00455\n",
            "time: 4.56 s (started: 2022-04-04 22:31:56 +02:00)\n"
          ]
        }
      ],
      "source": [
        "importlib.reload(modelLib)\n",
        "\n",
        "modelLib.train(instSet, model, hp, device, logDir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "foZTcBSWXDGp",
        "outputId": "c5ee5e74-792e-439b-a60a-3bf37b5843ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input ings: ['acorn squash', 'ground beef', 'salt', 'cinnamon', 'apples', 'raisins', 'salt', 'brown sugar', 'margarine']\n",
            "Input Title: Apple Filled Squash Halves\n",
            "Pred. Instructions:\n",
            "['bit individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual individual']\n",
            "time: 516 ms (started: 2022-04-04 22:32:01 +02:00)\n"
          ]
        }
      ],
      "source": [
        "importlib.reload(modelLib)\n",
        "\n",
        "idx = np.random.randint(0, len(testSet))\n",
        "inputIngs = testSet['ingredient'].values[idx]\n",
        "inputTitle = testSet['title'].values[idx]\n",
        "seq = modelLib.testInputPrep(inputIngs + inputTitle.split(), instSet.tokenizer)\n",
        "instPred = modelLib.sample(model, instSet.tokenizer, 300, device, initial=seq).split(instSet.delimiter)\n",
        "\n",
        "print('Input ings: {}\\nInput Title: {}\\nPred. Instructions:\\n{}'.format(inputIngs, inputTitle, instPred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 31 ms (started: 2022-04-04 22:32:01 +02:00)\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(),\n",
        "           saveDir + 'instGenerator_model_state_dict.pt')\n",
        "\n",
        "with open(saveDir + 'instTok.pkl', 'wb') as outp:\n",
        "    pickle.dump(instSet.tokenizer, outp, -1)\n",
        "\n",
        "with open(saveDir + 'hp.yml', 'w') as outp:\n",
        "    yaml.dump(dict(\n",
        "        epochs=hp.epochs,\n",
        "        batchSize=hp.batchSize,\n",
        "        lr=hp.lr,\n",
        "        ratio=hp.ratio,\n",
        "        hiddenDim=hp.hiddenDim,\n",
        "        numLayers=hp.numLayers,\n",
        "        embeddingDim=hp.embeddingDim,\n",
        "        delimiter=instSet.delimiter\n",
        "    ), outp, default_flow_style=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG3G4d4KYlxj"
      },
      "source": [
        "# Tensorboard visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\02_Studium\\\\SBX\\\\mad-recime\\\\network\\\\LSTM\\\\torch\\\\logs/instruction/'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 0 ns (started: 2022-04-04 22:32:02 +02:00)\n"
          ]
        }
      ],
      "source": [
        "# print path to logs that needs to be inserted for tensorboard\n",
        "logDir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NgcJKS4lfsY0",
        "outputId": "8b1fae5d-d406-45af-9c9b-e8de01116936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 3920), started 0:02:35 ago. (Use '!kill 3920' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-1fdce37c365af8f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-1fdce37c365af8f5\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 31 ms (started: 2022-04-04 22:32:02 +02:00)\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir='/content/drive/MyDrive/Colab Notebooks/recime/logs/instruction/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DhDetWcvllGW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPSgLtn3eqTae4YUZKrpVBR",
      "background_execution": "on",
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "instrGen.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "212bd27585ac1557bfa5ceb5c5ef7b9901e07084b14c30f3b6e0fbf0790365d6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('madEnv': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
