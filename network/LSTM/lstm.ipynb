{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mscholl96/mad-recime/blob/network_LSTM/network/LSTM/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzCPQy6dlIJK"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R3yLJ1_xBA2"
      },
      "source": [
        "## Basic includes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XN0Eb2xPKgV",
        "outputId": "ecefe638-475b-4d71-cd8f-8898cf45e00b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 934 µs (started: 2022-03-15 16:32:05 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jE0vTXeQQv_A",
        "outputId": "9acf1a64-146b-4962-9dd4-ea53750ec35e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word2vec\n",
            "  Downloading word2vec-0.11.1.tar.gz (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 810 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.21.5)\n",
            "Building wheels for collected packages: word2vec\n",
            "  Building wheel for word2vec (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2vec: filename=word2vec-0.11.1-py2.py3-none-any.whl size=156420 sha256=2231611931f1932b0d0c39c096ad7108ffb34e76a7e7b4744925d8493b508abe\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/c0/d4/29d797817e268124a32b6cf8beb8b8fe87b86f099d5a049e61\n",
            "Successfully built word2vec\n",
            "Installing collected packages: word2vec\n",
            "Successfully installed word2vec-0.11.1\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 52.7 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.5)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 75.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 80.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.11.2)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (3.0.7)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n",
            "Installing collected packages: deprecated, redis, grpcio, tensorboardX, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed deprecated-1.2.13 grpcio-1.43.0 ray-1.11.0 redis-4.1.4 tensorboardX-2.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "grpc"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 26.3 s (started: 2022-03-15 16:32:05 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install word2vec\n",
        "!pip install ray[tune]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9lWMi0pxADs",
        "outputId": "97c3efab-3f11-4761-a433-0f9ef264a943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 113 ms (started: 2022-03-15 16:32:31 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import word2vec\n",
        "from collections import Counter # https://pymotw.com/2/collections/counter.html\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import re\n",
        "import os\n",
        "\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06MHgolQxDOM",
        "outputId": "2187a32b-6ff7-406a-f562-7568ba859a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "time: 34.5 s (started: 2022-03-15 16:32:31 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "dataPath = '/content/drive/MyDrive/TP2/Datasets/Recipe1M/'\n",
        "import sys\n",
        "sys.path.append(dataPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEaAmmFMx-FW"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cLUewNUx_uv",
        "outputId": "7e3b2770-8d7b-43ec-954f-ce5e04d10ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 910 µs (started: 2022-03-15 16:33:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "TIMESTAMP = '2022_02_11'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "UOcytg8qyAvB",
        "outputId": "a182ac7f-3090-49a4-ad8b-019b00279fb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         title  \\\n",
              "id                                               \n",
              "000033e39b         Dilly Macaroni Salad Recipe   \n",
              "000035f7ed                            Gazpacho   \n",
              "00003a70b1           Crunchy Onion Potato Bake   \n",
              "00004320bb  Cool 'n Easy Creamy Watermelon Pie   \n",
              "0000631d90          Easy Tropical Beef Skillet   \n",
              "\n",
              "                                                  ingredients  \\\n",
              "id                                                              \n",
              "000033e39b     amount        unit       ingredient\n",
              "0    1....   \n",
              "000035f7ed     amount unit          ingredient\n",
              "0     8.0  ...   \n",
              "00003a70b1     amount   unit             ingredient\n",
              "0    2...   \n",
              "00004320bb     amount   unit            ingredient\n",
              "0    3....   \n",
              "0000631d90     amount        unit             ingredient\n",
              "0...   \n",
              "\n",
              "                                                 instructions  \n",
              "id                                                             \n",
              "000033e39b  0    Cook macaroni according to package direct...  \n",
              "000035f7ed  0    Add the tomatoes to a food processor with...  \n",
              "00003a70b1  0              Preheat oven to 350 degrees Fah...  \n",
              "00004320bb  0     Dissolve Jello in boiling water.\n",
              "1      ...  \n",
              "0000631d90  0    In a large skillet, toast the coconut ove...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec3f6f25-bd53-4c5f-a0ac-74e1ed936b81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>instructions</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000033e39b</th>\n",
              "      <td>Dilly Macaroni Salad Recipe</td>\n",
              "      <td>amount        unit       ingredient\n",
              "0    1....</td>\n",
              "      <td>0    Cook macaroni according to package direct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000035f7ed</th>\n",
              "      <td>Gazpacho</td>\n",
              "      <td>amount unit          ingredient\n",
              "0     8.0  ...</td>\n",
              "      <td>0    Add the tomatoes to a food processor with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00003a70b1</th>\n",
              "      <td>Crunchy Onion Potato Bake</td>\n",
              "      <td>amount   unit             ingredient\n",
              "0    2...</td>\n",
              "      <td>0              Preheat oven to 350 degrees Fah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00004320bb</th>\n",
              "      <td>Cool 'n Easy Creamy Watermelon Pie</td>\n",
              "      <td>amount   unit            ingredient\n",
              "0    3....</td>\n",
              "      <td>0     Dissolve Jello in boiling water.\n",
              "1      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0000631d90</th>\n",
              "      <td>Easy Tropical Beef Skillet</td>\n",
              "      <td>amount        unit             ingredient\n",
              "0...</td>\n",
              "      <td>0    In a large skillet, toast the coconut ove...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec3f6f25-bd53-4c5f-a0ac-74e1ed936b81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec3f6f25-bd53-4c5f-a0ac-74e1ed936b81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec3f6f25-bd53-4c5f-a0ac-74e1ed936b81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 28.4 s (started: 2022-03-15 16:33:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "baseFrame = pd.DataFrame()\n",
        "\n",
        "smallSet = True\n",
        "\n",
        "if(os.path.exists(dataPath + TIMESTAMP + '/recipes_valid_full.pkl')):\n",
        "  baseFrame = pd.read_pickle(dataPath + TIMESTAMP + '/recipes_valid_full.pkl')\n",
        "elif(smallSet == True):\n",
        "  baseFrame = baseFrame.append(pd.read_pickle(glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl')[0]))\n",
        "elif(len(glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl')) != 0):\n",
        "  for file in glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl'):\n",
        "    if not 'full' in file:\n",
        "      baseFrame = baseFrame.append(pd.read_pickle(file))\n",
        "\n",
        "baseFrame.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "OIncRPSKwy3r",
        "outputId": "c76f988c-4bb6-4f0f-e9c8-dea5b88f7058"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         title  \\\n",
              "id                                               \n",
              "000033e39b         Dilly Macaroni Salad Recipe   \n",
              "000035f7ed                            Gazpacho   \n",
              "00003a70b1           Crunchy Onion Potato Bake   \n",
              "00004320bb  Cool 'n Easy Creamy Watermelon Pie   \n",
              "0000631d90          Easy Tropical Beef Skillet   \n",
              "\n",
              "                                                 instructions  \\\n",
              "id                                                              \n",
              "000033e39b  0    Cook macaroni according to package direct...   \n",
              "000035f7ed  0    Add the tomatoes to a food processor with...   \n",
              "00003a70b1  0              Preheat oven to 350 degrees Fah...   \n",
              "00004320bb  0     Dissolve Jello in boiling water.\n",
              "1      ...   \n",
              "0000631d90  0    In a large skillet, toast the coconut ove...   \n",
              "\n",
              "                                                       amount  \\\n",
              "id                                                              \n",
              "000033e39b     [1.0, 1.0, 0.5, 0.5, 3.0, 0.5, 1.0, 0.75, 0.5]   \n",
              "000035f7ed      [8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 3.0]   \n",
              "00003a70b1               [2.5, 1.5, 0.25, 1.0, 8.0, 1.0, 1.0]   \n",
              "00004320bb                        [3.0, 0.25, 12.0, 2.0, 1.0]   \n",
              "0000631d90  [0.5, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 8.0, 16.0,...   \n",
              "\n",
              "                                                         unit  \\\n",
              "id                                                              \n",
              "000033e39b  [, , , , tablespoon, , tablespoon, teaspoon, t...   \n",
              "000035f7ed                                 [, , , , , , , , ]   \n",
              "00003a70b1                       [, , cup, , ounce, cup, cup]   \n",
              "00004320bb                         [ounce, cup, ounce, cup, ]   \n",
              "0000631d90  [cup, pound-mass, tablespoon, , tablespoon, ta...   \n",
              "\n",
              "                                                   ingredient  \n",
              "id                                                             \n",
              "000033e39b  [elbow macaroni, american cheese, celery, gree...  \n",
              "000035f7ed  [tomatoes, kosher salt, red onion, green bell ...  \n",
              "00003a70b1  [milk, water, butter, mashed potatoes, whole k...  \n",
              "00004320bb  [watermelon gelatin, boiling water, cool whip,...  \n",
              "0000631d90  [shredded coconut, lean ground beef, fresh gar...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-971717d6-70e0-4e08-8042-0a99fca3cad8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>instructions</th>\n",
              "      <th>amount</th>\n",
              "      <th>unit</th>\n",
              "      <th>ingredient</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000033e39b</th>\n",
              "      <td>Dilly Macaroni Salad Recipe</td>\n",
              "      <td>0    Cook macaroni according to package direct...</td>\n",
              "      <td>[1.0, 1.0, 0.5, 0.5, 3.0, 0.5, 1.0, 0.75, 0.5]</td>\n",
              "      <td>[, , , , tablespoon, , tablespoon, teaspoon, t...</td>\n",
              "      <td>[elbow macaroni, american cheese, celery, gree...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000035f7ed</th>\n",
              "      <td>Gazpacho</td>\n",
              "      <td>0    Add the tomatoes to a food processor with...</td>\n",
              "      <td>[8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 3.0]</td>\n",
              "      <td>[, , , , , , , , ]</td>\n",
              "      <td>[tomatoes, kosher salt, red onion, green bell ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00003a70b1</th>\n",
              "      <td>Crunchy Onion Potato Bake</td>\n",
              "      <td>0              Preheat oven to 350 degrees Fah...</td>\n",
              "      <td>[2.5, 1.5, 0.25, 1.0, 8.0, 1.0, 1.0]</td>\n",
              "      <td>[, , cup, , ounce, cup, cup]</td>\n",
              "      <td>[milk, water, butter, mashed potatoes, whole k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00004320bb</th>\n",
              "      <td>Cool 'n Easy Creamy Watermelon Pie</td>\n",
              "      <td>0     Dissolve Jello in boiling water.\n",
              "1      ...</td>\n",
              "      <td>[3.0, 0.25, 12.0, 2.0, 1.0]</td>\n",
              "      <td>[ounce, cup, ounce, cup, ]</td>\n",
              "      <td>[watermelon gelatin, boiling water, cool whip,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0000631d90</th>\n",
              "      <td>Easy Tropical Beef Skillet</td>\n",
              "      <td>0    In a large skillet, toast the coconut ove...</td>\n",
              "      <td>[0.5, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 8.0, 16.0,...</td>\n",
              "      <td>[cup, pound-mass, tablespoon, , tablespoon, ta...</td>\n",
              "      <td>[shredded coconut, lean ground beef, fresh gar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-971717d6-70e0-4e08-8042-0a99fca3cad8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-971717d6-70e0-4e08-8042-0a99fca3cad8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-971717d6-70e0-4e08-8042-0a99fca3cad8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2min 52s (started: 2022-03-15 16:33:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# todo: move to dataset class\n",
        "def flatten_ing(row):\n",
        "  row['amount'] = row['ingredients']['amount'].tolist()\n",
        "  row['unit'] = row['ingredients']['unit'].tolist()\n",
        "  row['ingredient'] = row['ingredients']['ingredient'].tolist()\n",
        "  return row\n",
        "\n",
        "baseFrame = baseFrame.apply(flatten_ing, axis=1)\n",
        "baseFrame = baseFrame.drop(columns=['ingredients'])\n",
        "\n",
        "baseFrame.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-ICdtLwBEM_"
      },
      "source": [
        "## Brainstorming\n",
        "* not a simple sequence\n",
        "* basically sequence of\n",
        "  * ingredients\n",
        "  * set of instructions --> instruction --> words\n",
        "* maybe instead of instructions sequences, instructions could be flattened and split signs (.,!?;) also learned (in case learning sentence sequences is not possible)\n",
        "\n",
        "Maybe stacked LSTMs are a solutions\n",
        "* train how instructions in general are to be composed\n",
        "* train how instructions are combined to a set of instructions\n",
        "\n",
        "Input\n",
        "* ingredients to be used as input\n",
        "* to not train on instructions to appear according to ingredients sequence, maybe randomly shuffle ingredients but keep instruction set the same\n",
        "* \n",
        "\n",
        "https://www.youtube.com/watch?v=A9QVYOBjZdY&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S&index=5&ab_channel=TensorFlow\n",
        "\n",
        "\n",
        "## Differentiation\n",
        "* Title generation based on ingredients\n",
        "* instruction generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf20_SrBw-i-"
      },
      "source": [
        "## Imports for Learning\n",
        "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwzWep0k_99",
        "outputId": "ee78ab62-e080-4142-8366-b607d1b76c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.61 s (started: 2022-03-15 16:36:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable \n",
        "from torchsummary import summary\n",
        "\n",
        "# Optimizer\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# Tokenizer\n",
        "# torch padding does only support constant padding (ConstantPad1d) for 1D or non-constant padding for >1D (nn.function.pad)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# keras tokenizer more powerful than torch\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from torchtext.data import get_tokenizer # https://pytorch.org/text/stable/data_utils.html\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "# hyperparameter tuning\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pOeZxpgBOaY"
      },
      "source": [
        "# Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjrp4aPbBL-r",
        "outputId": "db1dd7e2-75fd-4f40-ca70-4ae099d83776"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f732aa37590>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.63 ms (started: 2022-03-15 16:36:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIhRxE1cj5ps"
      },
      "source": [
        "# Setup\n",
        "https://closeheat.com/blog/pytorch-lstm-text-generation-tutorial\n",
        "\n",
        "\n",
        "## Tokenization\n",
        "to be checked: necessity of punctuation (maybe reintroduce later: https://stackoverflow.com/questions/49073673/include-punctuation-in-keras-tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5XkLuiCIbKS"
      },
      "source": [
        "### Get Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jER6BpRl8ikx",
        "outputId": "97f47aa9-abec-41bc-9f48-a954ddc0a24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab.bin not to be used as dict misses words\n",
            "time: 1.82 s (started: 2022-03-15 16:36:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "w2v_model = word2vec.load(dataPath + 'vocab.bin')\n",
        "ingredientDict = {}\n",
        "for voc in w2v_model.vocab:\n",
        "     # Offset by 1 so empty fields can be 0\n",
        "     ingredientDict.setdefault(voc, len(ingredientDict)+1)\n",
        "\n",
        "if 'dilly' in ingredientDict:\n",
        "  print(\"Word exists\")\n",
        "else:\n",
        "  print('vocab.bin not to be used as dict misses words') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyxLsHZmQ0_o",
        "outputId": "946d7d20-bccb-4043-e8da-8798f8a208d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.88 s (started: 2022-03-15 16:36:36 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def getCorpus(title, ingredient, instructions):\n",
        "  titleTok = text_to_word_sequence(title)\n",
        "  ingTok = text_to_word_sequence(' '.join(ingredient))\n",
        "  instTok = text_to_word_sequence(' '.join(instructions))\n",
        "  return np.array(ingTok + titleTok + instTok)\n",
        "\n",
        "corpus = np.vectorize(getCorpus, otypes=[np.ndarray])(baseFrame['title'], baseFrame['ingredient'], baseFrame['instructions'])\n",
        "corpus = np.concatenate(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tmFQxxDKSW9"
      },
      "source": [
        "###  Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VbmOw8mDyOP",
        "outputId": "e2995d59-0f20-4d2b-9c77-d5dde9115e7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ings': ['elbow',\n",
              "  'macaroni',\n",
              "  'american',\n",
              "  'cheese',\n",
              "  'celery',\n",
              "  'green',\n",
              "  'peppers',\n",
              "  'pimentos',\n",
              "  'mayonnaise',\n",
              "  'vinegar',\n",
              "  'salt',\n",
              "  'dry',\n",
              "  'dill',\n",
              "  'weed'],\n",
              " 'title': ['dilly', 'macaroni', 'salad', 'recipe']}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.35 ms (started: 2022-03-15 16:36:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "test = baseFrame.head(20).copy()\n",
        "\n",
        "def getTitleSequence(title, ingredient):\n",
        "  titleTok = text_to_word_sequence(title)\n",
        "  ingTok = text_to_word_sequence(','.join(ingredient))\n",
        "  return {'ings': ingTok, 'title': titleTok}\n",
        "\n",
        "titleSeq = np.vectorize(getTitleSequence, otypes=[np.ndarray])(test['title'], test['ingredient'])\n",
        "titleSeq[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbb9g8Xkex5A",
        "outputId": "95804862-1645-4b52-c99d-a30d2a7e5503"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['elbow', 'macaroni', 'american', 'cheese', 'celery', 'green',\n",
              "        'peppers', 'pimentos', 'mayonnaise', 'vinegar', 'salt', 'dry',\n",
              "        'dill', 'weed'], dtype='<U32'),\n",
              " array(['macaroni', 'american', 'cheese', 'celery', 'green', 'peppers',\n",
              "        'pimentos', 'mayonnaise', 'vinegar', 'salt', 'dry', 'dill', 'weed',\n",
              "        'dilly'], dtype='<U32'))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.4 ms (started: 2022-03-15 16:36:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def getNGramSeq(seq):\n",
        "  # input needs to be pre padded\n",
        "  idxShift = len(seq['title'])\n",
        "  ingLen = len(seq['ings'])\n",
        "  fullSeq = np.array(seq['ings'] + seq['title'])\n",
        "  retSeq = np.empty((0,ingLen + 1))\n",
        "  for i_shift in range(idxShift):\n",
        "    retSeq = np.vstack([retSeq, np.array(fullSeq[i_shift:ingLen+i_shift+1])])\n",
        "  return retSeq\n",
        "\n",
        "ngramSeq = pd.Series(np.vectorize(getNGramSeq, otypes=[np.ndarray])(titleSeq)).explode().to_numpy()\n",
        "ngramSeq[0][:-1], ngramSeq[0][1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTSZL7Xka-qr"
      },
      "source": [
        "### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGKlvcMia9Ts",
        "outputId": "75575b0b-e89a-40cf-f7ae-0cd705cd8931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.79 ms (started: 2022-03-15 16:36:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class HyperParams():\n",
        "  def __init__(self, epochs=10, batchSize=10, lr=1e-3, trainValRatio=[0.7, 0.3]):\n",
        "    self.epochs = range(1, epochs+1)\n",
        "    self.batchSize = batchSize\n",
        "    self.lr = lr\n",
        "    self.trainValRatio = trainValRatio\n",
        "\n",
        "    self.input_size = 5 #number of features\n",
        "    self.hidden_dim = 4 #number of features in hidden state\n",
        "    self.num_layers = 1 #number of stacked lstm layers\n",
        "    self.num_classes = 1 #number of output classes \n",
        "    self.embedding_dim = 4 # embedding dimension\n",
        "\n",
        "  def __str__(self):\n",
        "    return('epochs ' + str(self.epochs) + '\\n' +\n",
        "    'batchSize ' + str(self.batchSize) + '\\n' +\n",
        "    'lr ' + str(self.lr) + '\\n' +\n",
        "    'trainValRatio ' + str(self.trainValRatio) + '\\n' +\n",
        "    'input_size ' + str(self.input_size) + '\\n' +\n",
        "    'hidden_dim ' + str(self.hidden_dim) + '\\n' +\n",
        "    'num_layers ' + str(self.num_layers) + '\\n' +\n",
        "    'num_classes ' + str(self.num_classes) + '\\n' +\n",
        "    'embedding_dim ' + str(self.embedding_dim) + '\\n')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcnDjUaHKVHn"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRKA1xo1thoy",
        "outputId": "20b48d04-21de-4b85-8695-2e2c8c68312f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 49.1 ms (started: 2022-03-15 16:36:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Data (https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)\n",
        "class TitleDataset(Dataset):\n",
        "    def __init__(self, hyperparams, data):\n",
        "      self.hyperparams = hyperparams\n",
        "\n",
        "      self.tokenizer = Tokenizer()\n",
        "\n",
        "      # dataset split into word sequences required for training\n",
        "      self.wordSeq = np.vectorize(self.getTitleSequence, otypes=[np.ndarray])(data['title'], data['ingredient'])\n",
        "\n",
        "      # training requires same length sequences -->  padding\n",
        "      self.maxSequenceLength = max([max(len(seq['ings']), len(seq['title'])) for seq in self.wordSeq])\n",
        "\n",
        "      # list of all words in dataset\n",
        "      self.words = np.concatenate(np.vectorize(self.getCorpus, otypes=[np.ndarray])(data['title'], data['ingredient'], data['instructions']))\n",
        "\n",
        "      # tokenization corpus\n",
        "      self.tokenizer.fit_on_texts(self.words)\n",
        "\n",
        "      # indexed wordSequences (could be calculated in getter but very slow, preprocessing better)\n",
        "      self.idxWords = np.vectorize(self.getIndexedSeqs, otypes=[np.ndarray])(self.wordSeq)\n",
        "\n",
        "      # n gram sequences\n",
        "      self.ngramSeq = pd.Series(np.vectorize(self.getNGramSeq, otypes=[np.ndarray])(self.idxWords)).explode().to_numpy()\n",
        "\n",
        "\n",
        "    def getCorpus(self, title, ingredient, instructions):\n",
        "      titleTok = text_to_word_sequence(title)\n",
        "      ingTok = text_to_word_sequence(','.join(ingredient))\n",
        "      # instTok = text_to_word_sequence('\\n'.join(instructions)) # TODO: remove\n",
        "      return np.array(ingTok + titleTok)# + instTok)\n",
        "\n",
        "    def getTitleSequence(self, title, ingredient):\n",
        "      titleTok = text_to_word_sequence(title)\n",
        "      ingTok = text_to_word_sequence(','.join(ingredient))\n",
        "      return {'ings': ingTok, 'title': titleTok}\n",
        "\n",
        "    def getIndexedSeqs(self, seq):\n",
        "      ingTok = self.tokenizer.texts_to_sequences([seq['ings']])[0]\n",
        "      ingTok = pad_sequences([ingTok], maxlen=self.maxSequenceLength, padding='pre')[0] # https://arxiv.org/abs/1903.07288\n",
        "      titleTok = self.tokenizer.texts_to_sequences([seq['title']])[0]\n",
        "      # titleTok = pad_sequences([titleTok], maxlen=self.maxSequenceLength, padding='post')[0] # post in order to get oov to indicate end of title\n",
        "\n",
        "      return {'ings': ingTok, 'title': titleTok}\n",
        "\n",
        "    def getNGramSeq(self, seq):\n",
        "      # input needs to be pre padded\n",
        "      idxShift = len(seq['title'])\n",
        "      ingLen = len(seq['ings'])\n",
        "\n",
        "      fullSeq = np.append(seq['ings'], seq['title'])\n",
        "      retSeq = np.empty((0,ingLen + 1), dtype=np.int32)\n",
        "\n",
        "      for i_shift in range(idxShift):\n",
        "        retSeq = np.vstack([retSeq, np.array(fullSeq[i_shift:ingLen+i_shift+1])])\n",
        "      return retSeq\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxWords)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # tuple of input (ingredients) and label (title)\n",
        "        return (\n",
        "            torch.tensor(self.ngramSeq[index][:-1]),\n",
        "            torch.tensor(self.ngramSeq[index][1:])\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gukTWG9C5kAR"
      },
      "source": [
        "## Model\n",
        "LSTM Net: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "\n",
        "Embedding Net: https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
        "\n",
        "Init state: https://stats.stackexchange.com/questions/224737/best-way-to-initialize-lstm-state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtJQI0JktCJe"
      },
      "source": [
        "### base: https://cnvrg.io/pytorch-lstm/\n",
        "Without embedding layer before --> todo: check how this is better/worse\n",
        "\n",
        "### base: https://github.com/yuchenlin/lstm_sentence_classifier/blob/master/LSTM_sentence_classifier.py\n",
        "\n",
        "### base: https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdhkbXIio_f3"
      },
      "source": [
        "### base: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#lstms-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XByY-PwpBlI",
        "outputId": "441ab879-6445-4f41-eb52-50a45f1dd20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 18.7 ms (started: 2022-03-15 18:17:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Model3(nn.Module):\n",
        "\n",
        "    def __init__(self, hyperParams, dataset, device):\n",
        "        super(Model3, self).__init__()\n",
        "\n",
        "        # initialize vital params\n",
        "        self.vocab_size = len(dataset.tokenizer.word_index)\n",
        "        self.batchSize = hyperParams.batchSize\n",
        "        self.hidden_dim = hyperParams.hidden_dim\n",
        "        self.device = device\n",
        "        self.num_layers = hyperParams.num_layers\n",
        "        \n",
        "        # embedding definition \n",
        "        self.word_embeddings = nn.Embedding(self.vocab_size, hyperParams.embedding_dim)\n",
        "\n",
        "        # lstm definition\n",
        "        self.lstm = nn.LSTM(input_size=hyperParams.embedding_dim, hidden_size=hyperParams.hidden_dim, num_layers=self.num_layers, batch_first=True)\n",
        "\n",
        "        # definition fully connected layer\n",
        "        self.hidden2label = nn.Linear(hyperParams.hidden_dim, self.vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embeds = self.word_embeddings(x)\n",
        "\n",
        "        lstm_out, (h_t, c_t) = self.lstm(embeds, hidden)\n",
        "\n",
        "        out = self.hidden2label(lstm_out.reshape(-1, self.hidden_dim))\n",
        "        # tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return out, (h_t, c_t)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        ''' initializes hidden state '''\n",
        "        # Create two new tensors with sizes num_layers x batchSize x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        hidden = (weight.new(self.num_layers, self.batchSize, self.hidden_dim).zero_().cuda(),#to(self.device),\n",
        "                  weight.new(self.num_layers, self.batchSize, self.hidden_dim).zero_().cuda())#to(self.device))\n",
        "        \n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyuY9T8a5pqr"
      },
      "source": [
        "## Training\n",
        "mixture of \n",
        "* https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
        "* https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
        "* https://stackoverflow.com/questions/67295494/correct-validation-loss-in-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U258NxuRDRRx",
        "outputId": "23f6b425-59d5-4bb8-b3e6-5bf0ab97f8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 66.5 ms (started: 2022-03-15 18:48:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def train(dataset, model, hyperparams, device):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
        "\n",
        "  # split data\n",
        "  train_set, val_set = random_split(dataset, [int(hyperparams.trainValRatio[0] * len(dataset)), int(hyperparams.trainValRatio[1] * len(dataset))], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "  train_loader = DataLoader(train_set, batch_size=hyperparams.batchSize)\n",
        "  val_loader   = DataLoader(val_set, batch_size=hyperparams.batchSize)\n",
        "  # further options: shuffle, num_workers\n",
        "\n",
        "  for epoch in hyperparams.epochs:\n",
        "    running_loss = 0.\n",
        "    epoch_steps = 0\n",
        "    counter = 0\n",
        "\n",
        "    h = model.init_hidden()\n",
        "\n",
        "    model.train() # what does it do\n",
        "\n",
        "    for batch, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "      # assign inputs and labels to device\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "      # detach hidden states\n",
        "      h = tuple([each.data for each in h])\n",
        "\n",
        "      # clear gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # batch prediction (alternative: forward)\n",
        "      # print('Sentence: ' + str(inputs.shape))\n",
        "      outputs, h = model(inputs, h)\n",
        "      # outputs = outputs.to(device)\n",
        "      labels = labels.long()\n",
        "\n",
        "      # loss computation\n",
        "      # print('Outputs: ' + str(outputs.shape))\n",
        "      # print('Labels: ' + str(labels.shape))\n",
        "\n",
        "      loss = criterion(outputs, labels.view(-1))\n",
        "\n",
        "      # calc backward gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # run optimizer\n",
        "      optimizer.step()\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      epoch_steps += 1\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, running_loss / epoch_steps)) \n",
        "      running_loss = 0.0\n",
        "\n",
        "      \n",
        "    # Validation Loss\n",
        "    # correct = 0                                               \n",
        "    # total = 0                                                 \n",
        "    # running_loss = 0.0    \n",
        "    # val_steps = 0                                    \n",
        "    \n",
        "    # model.eval() # what does it do\n",
        "    # with torch.no_grad(): # what does it do\n",
        "    #   for batch, (inputs, labels) in enumerate(val_loader):\n",
        "    #     # assign inputs and labels to device\n",
        "    #     input, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    #     # batch prediction (alternative: forward)\n",
        "    #     outputs, h = model(inputs, h)\n",
        "    #     # outputs = outputs.to(device)\n",
        "    #     labels = labels.long()\n",
        "\n",
        "    #     # loss computation\n",
        "    #     loss = criterion(outputs, labels.view(-1))\n",
        "\n",
        "    #     # _, predicted = torch.max(outputs.data, 1)\n",
        "    #     # total += labels.size(0)\n",
        "    #     # correct += (predicted == labels).sum().item()\n",
        "\n",
        "    #     running_loss += loss.item()\n",
        "    #     val_steps += 1\n",
        "\n",
        "    # # mean_val_accuracy = (100 * correct / total)               \n",
        "    # mean_val_loss = ( running_loss )                  \n",
        "    # # print('Validation Accuracy: %d %%' % (mean_val_accuracy)) \n",
        "    # print('Validation Loss:'  ,mean_val_loss )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov7EPe_eqmbP",
        "outputId": "0deed8bc-f121-4e80-d7b7-0e9c0be92612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.6 ms (started: 2022-03-15 17:19:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def predict(dataset, model, words, next_words=100):\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "    title = []\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.tokenizer.word_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.tokenizer.sequences_to_texts([[word_index]])[0])\n",
        "        title.append(dataset.tokenizer.sequences_to_texts([[word_index]])[0])\n",
        "\n",
        "    return title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9EsSXZ7DEI1"
      },
      "source": [
        "# USE TENSORBOARXD (looks fancy, good for analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdDLkBBLbNiz"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHdjyULcN1d1",
        "outputId": "a1194b00-7b78-4d03-ae0f-58c44f27f3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs range(1, 51)\n",
            "batchSize 10\n",
            "lr 0.001\n",
            "trainValRatio [0.7, 0.3]\n",
            "input_size 5\n",
            "hidden_dim 4\n",
            "num_layers 1\n",
            "num_classes 1\n",
            "embedding_dim 4\n",
            "\n",
            "time: 1.1 ms (started: 2022-03-15 18:56:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "hyperParams = HyperParams(epochs=50)\n",
        "print(hyperParams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWe4t2xp_Ieg",
        "outputId": "f20fd5a0-ac91-4afd-aea1-bdafc86a72aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 23.5 s (started: 2022-03-15 18:56:04 +00:00)\n"
          ]
        }
      ],
      "source": [
        "titleSet = TitleDataset(hyperParams, baseFrame)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# titleSet.tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeaBIyy6mfqR",
        "outputId": "83c0114e-2a4e-42c6-8bb3-592e3a996181"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 781 µs (started: 2022-03-15 18:56:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cAHwy4Y13_r",
        "outputId": "493b3201-8da6-4318-86c6-3ee690f3eb02"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "time: 1.38 ms (started: 2022-03-15 18:56:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOYpjAPHE3HY",
        "outputId": "208ec19c-3f28-4bf5-9f3b-ff4199c2889a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model3(\n",
            "  (word_embeddings): Embedding(19623, 4)\n",
            "  (lstm): LSTM(4, 4, batch_first=True)\n",
            "  (hidden2label): Linear(in_features=4, out_features=19623, bias=True)\n",
            ")\n",
            "time: 5.72 ms (started: 2022-03-15 18:56:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model = Model3(hyperParams, titleSet, device)\n",
        "model.to(device)\n",
        "print(model)\n",
        "# summary(model, (16,53))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(titleSet, batch_size=hyperParams.batchSize)\n",
        "for batch, (inputs, labels) in enumerate(train_loader):\n",
        "  print(len(inputs[0]))\n",
        "  inputs, labels = inputs.to(device), labels.to(device)\n",
        "  test = model.word_embeddings(inputs)\n",
        "  print(test.shape)\n",
        "  lstm_out, _ = model.lstm(test.view(len(inputs[0]), model.batchSize, -1))\n",
        "  print(lstm_out.shape)\n",
        "  break;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V9Ce_Wuwour",
        "outputId": "7b97a012-3e90-47a6-b527-bdd9662cf0a5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n",
            "torch.Size([10, 53, 4])\n",
            "torch.Size([53, 10, 4])\n",
            "time: 6.41 ms (started: 2022-03-15 18:56:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "CL4vqYn0aXXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb5b89c-c55d-4537-cb0a-27bdc13167d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, loss: 3.02835\n",
            "Epoch: 2, loss: 2.25297\n",
            "Epoch: 3, loss: 2.16502\n",
            "Epoch: 4, loss: 2.12041\n",
            "Epoch: 5, loss: 2.08132\n",
            "Epoch: 6, loss: 2.04739\n",
            "Epoch: 7, loss: 2.02484\n",
            "Epoch: 8, loss: 2.00761\n",
            "Epoch: 9, loss: 1.98797\n",
            "Epoch: 10, loss: 1.96903\n",
            "Epoch: 11, loss: 1.95681\n",
            "Epoch: 12, loss: 1.94544\n",
            "Epoch: 13, loss: 1.93579\n",
            "Epoch: 14, loss: 1.92786\n",
            "Epoch: 15, loss: 1.92115\n",
            "Epoch: 16, loss: 1.91499\n",
            "Epoch: 17, loss: 1.90953\n",
            "Epoch: 18, loss: 1.90516\n",
            "Epoch: 19, loss: 1.90131\n",
            "Epoch: 20, loss: 1.89726\n",
            "Epoch: 21, loss: 1.89378\n",
            "Epoch: 22, loss: 1.89085\n",
            "Epoch: 23, loss: 1.88820\n",
            "Epoch: 24, loss: 1.88578\n",
            "Epoch: 25, loss: 1.88353\n",
            "Epoch: 26, loss: 1.88126\n",
            "Epoch: 27, loss: 1.87908\n",
            "Epoch: 28, loss: 1.87713\n",
            "Epoch: 29, loss: 1.87527\n",
            "Epoch: 30, loss: 1.87362\n",
            "Epoch: 31, loss: 1.87208\n",
            "Epoch: 32, loss: 1.87066\n",
            "Epoch: 33, loss: 1.86934\n",
            "Epoch: 34, loss: 1.86807\n",
            "Epoch: 35, loss: 1.86682\n",
            "Epoch: 36, loss: 1.86569\n",
            "Epoch: 37, loss: 1.86457\n",
            "Epoch: 38, loss: 1.86335\n",
            "Epoch: 39, loss: 1.86229\n",
            "Epoch: 40, loss: 1.86131\n",
            "Epoch: 41, loss: 1.86035\n",
            "Epoch: 42, loss: 1.85930\n",
            "Epoch: 43, loss: 1.85843\n",
            "Epoch: 44, loss: 1.85763\n",
            "Epoch: 45, loss: 1.85686\n",
            "Epoch: 46, loss: 1.85610\n",
            "Epoch: 47, loss: 1.85538\n",
            "Epoch: 48, loss: 1.85468\n",
            "Epoch: 49, loss: 1.85400\n",
            "Epoch: 50, loss: 1.85335\n",
            "time: 24min 59s (started: 2022-03-15 18:56:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train(titleSet, model, hyperParams, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "vtWOfGAu_HwF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "89a23933-ec70-4edc-9e69-232ab4a6b260"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-07bc09269c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m print('Orig: ' + str(titleSet.wordSeq[idx]['title']) + '\\n' + \n\u001b[0;32m----> 3\u001b[0;31m       'Predict: ' + str(predict(titleSet, model, words=titleSet.wordSeq[idx]['ings'], next_words=len(titleSet.wordSeq[idx]['title']))))\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-c4ddefbaf172>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(dataset, model, words, next_words)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Model3' object has no attribute 'init_state'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 29.5 ms (started: 2022-03-15 19:21:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "idx = 100\n",
        "print('Orig: ' + str(titleSet.wordSeq[idx]['title']) + '\\n' + \n",
        "      'Predict: ' + str(predict(titleSet, model, words=titleSet.wordSeq[idx]['ings'], next_words=len(titleSet.wordSeq[idx]['title']))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP-vdHzHo-Q8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R5mHJ-WY8UJ"
      },
      "outputs": [],
      "source": [
        "a = torch.randn(4, 4)\n",
        "a.shape\n",
        "torch.argmax(a, dim=1, keepdim=True).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/lstm-for-time-series-prediction-de8aeb26f2ca for input sequence"
      ],
      "metadata": {
        "id": "ViDsBEbBtFcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xs5F1dsDrOLH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "lstm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPM/00J700bMSGPe5kDpbfU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}