{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPhOBEApXlYx+kdeL+JUmq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mscholl96/mad-recime/blob/network_LSTM/network/LSTM/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
      ],
      "metadata": {
        "id": "vzCPQy6dlIJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic includes"
      ],
      "metadata": {
        "id": "8R3yLJ1_xBA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XN0Eb2xPKgV",
        "outputId": "81355782-5bbf-43b7-e4cb-f3a8695d79aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 530 µs (started: 2022-02-20 09:22:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install word2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE0vTXeQQv_A",
        "outputId": "1673287e-0e7b-4427-e6db-71b2010f08d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word2vec\n",
            "  Downloading word2vec-0.11.1.tar.gz (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 39.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 45.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.21.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.1.0)\n",
            "Building wheels for collected packages: word2vec\n",
            "  Building wheel for word2vec (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2vec: filename=word2vec-0.11.1-py2.py3-none-any.whl size=156420 sha256=9783e4fe371713333c119cbb4ca8d521b647ea2dedf00a9ffd1e149b20969f61\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/c0/d4/29d797817e268124a32b6cf8beb8b8fe87b86f099d5a049e61\n",
            "Successfully built word2vec\n",
            "Installing collected packages: word2vec\n",
            "Successfully installed word2vec-0.11.1\n",
            "time: 14.2 s (started: 2022-02-20 09:22:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import word2vec\n",
        "from collections import Counter # https://pymotw.com/2/collections/counter.html\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import re\n",
        "import os\n",
        "\n",
        "import glob"
      ],
      "metadata": {
        "id": "e9lWMi0pxADs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507240a6-e9a1-4249-bf8d-02f30780dca2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 47.1 ms (started: 2022-02-20 09:22:25 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "dataPath = '/content/drive/MyDrive/TP2/Datasets/Recipe1M/'\n",
        "import sys\n",
        "sys.path.append(dataPath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06MHgolQxDOM",
        "outputId": "b08e5c5d-4c3c-43f8-8a89-fd92dbc0f451"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "time: 1min 3s (started: 2022-02-20 09:22:25 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "wEaAmmFMx-FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TIMESTAMP = '2022_02_11'"
      ],
      "metadata": {
        "id": "9cLUewNUx_uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de02e85c-f6e8-4677-a427-375dc367307e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 894 µs (started: 2022-02-20 09:23:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseFrame = pd.DataFrame()\n",
        "\n",
        "smallSet = True\n",
        "\n",
        "if(os.path.exists(dataPath + TIMESTAMP + '/recipes_valid_full.pkl')):\n",
        "  baseFrame = pd.read_pickle(dataPath + TIMESTAMP + '/recipes_valid_full.pkl')\n",
        "elif(smallSet == True):\n",
        "  baseFrame = baseFrame.append(pd.read_pickle(glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl')[0]))\n",
        "elif(len(glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl')) != 0):\n",
        "  for file in glob.glob(dataPath + TIMESTAMP +  '/recipes_valid_*.pkl'):\n",
        "    if not 'full' in file:\n",
        "      baseFrame = baseFrame.append(pd.read_pickle(file))\n",
        "\n",
        "baseFrame.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "UOcytg8qyAvB",
        "outputId": "75ea7144-6b54-4165-9c75-5b2b0325c3a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d106c550-8f3b-4f46-bbab-7ed32a150f36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>instructions</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000033e39b</th>\n",
              "      <td>Dilly Macaroni Salad Recipe</td>\n",
              "      <td>amount        unit       ingredient\n",
              "0    1....</td>\n",
              "      <td>0    Cook macaroni according to package direct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000035f7ed</th>\n",
              "      <td>Gazpacho</td>\n",
              "      <td>amount unit          ingredient\n",
              "0     8.0  ...</td>\n",
              "      <td>0    Add the tomatoes to a food processor with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00003a70b1</th>\n",
              "      <td>Crunchy Onion Potato Bake</td>\n",
              "      <td>amount   unit             ingredient\n",
              "0    2...</td>\n",
              "      <td>0              Preheat oven to 350 degrees Fah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00004320bb</th>\n",
              "      <td>Cool 'n Easy Creamy Watermelon Pie</td>\n",
              "      <td>amount   unit            ingredient\n",
              "0    3....</td>\n",
              "      <td>0     Dissolve Jello in boiling water.\n",
              "1      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0000631d90</th>\n",
              "      <td>Easy Tropical Beef Skillet</td>\n",
              "      <td>amount        unit             ingredient\n",
              "0...</td>\n",
              "      <td>0    In a large skillet, toast the coconut ove...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d106c550-8f3b-4f46-bbab-7ed32a150f36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d106c550-8f3b-4f46-bbab-7ed32a150f36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d106c550-8f3b-4f46-bbab-7ed32a150f36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         title  ...                                       instructions\n",
              "id                                              ...                                                   \n",
              "000033e39b         Dilly Macaroni Salad Recipe  ...  0    Cook macaroni according to package direct...\n",
              "000035f7ed                            Gazpacho  ...  0    Add the tomatoes to a food processor with...\n",
              "00003a70b1           Crunchy Onion Potato Bake  ...  0              Preheat oven to 350 degrees Fah...\n",
              "00004320bb  Cool 'n Easy Creamy Watermelon Pie  ...  0     Dissolve Jello in boiling water.\n",
              "1      ...\n",
              "0000631d90          Easy Tropical Beef Skillet  ...  0    In a large skillet, toast the coconut ove...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 28.5 s (started: 2022-02-20 09:23:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_ing(row):\n",
        "  row['amount'] = row['ingredients']['amount'].tolist()\n",
        "  row['unit'] = row['ingredients']['unit'].tolist()\n",
        "  row['ingredient'] = row['ingredients']['ingredient'].tolist()\n",
        "  return row\n",
        "\n",
        "baseFrame = baseFrame.apply(flatten_ing, axis=1)\n",
        "baseFrame = baseFrame.drop(columns=['ingredients'])\n",
        "\n",
        "baseFrame.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "OIncRPSKwy3r",
        "outputId": "fd3386b3-fb61-4d65-adb3-19f17c8f5282"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9cd62ea7-0c7c-40b9-a472-14c2500b9a0e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>instructions</th>\n",
              "      <th>amount</th>\n",
              "      <th>unit</th>\n",
              "      <th>ingredient</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000033e39b</th>\n",
              "      <td>Dilly Macaroni Salad Recipe</td>\n",
              "      <td>0    Cook macaroni according to package direct...</td>\n",
              "      <td>[1.0, 1.0, 0.5, 0.5, 3.0, 0.5, 1.0, 0.75, 0.5]</td>\n",
              "      <td>[, , , , tablespoon, , tablespoon, teaspoon, t...</td>\n",
              "      <td>[elbow macaroni, american cheese, celery, gree...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000035f7ed</th>\n",
              "      <td>Gazpacho</td>\n",
              "      <td>0    Add the tomatoes to a food processor with...</td>\n",
              "      <td>[8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 3.0]</td>\n",
              "      <td>[, , , , , , , , ]</td>\n",
              "      <td>[tomatoes, kosher salt, red onion, green bell ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00003a70b1</th>\n",
              "      <td>Crunchy Onion Potato Bake</td>\n",
              "      <td>0              Preheat oven to 350 degrees Fah...</td>\n",
              "      <td>[2.5, 1.5, 0.25, 1.0, 8.0, 1.0, 1.0]</td>\n",
              "      <td>[, , cup, , ounce, cup, cup]</td>\n",
              "      <td>[milk, water, butter, mashed potatoes, whole k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00004320bb</th>\n",
              "      <td>Cool 'n Easy Creamy Watermelon Pie</td>\n",
              "      <td>0     Dissolve Jello in boiling water.\n",
              "1      ...</td>\n",
              "      <td>[3.0, 0.25, 12.0, 2.0, 1.0]</td>\n",
              "      <td>[ounce, cup, ounce, cup, ]</td>\n",
              "      <td>[watermelon gelatin, boiling water, cool whip,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0000631d90</th>\n",
              "      <td>Easy Tropical Beef Skillet</td>\n",
              "      <td>0    In a large skillet, toast the coconut ove...</td>\n",
              "      <td>[0.5, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 8.0, 16.0,...</td>\n",
              "      <td>[cup, pound-mass, tablespoon, , tablespoon, ta...</td>\n",
              "      <td>[shredded coconut, lean ground beef, fresh gar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cd62ea7-0c7c-40b9-a472-14c2500b9a0e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9cd62ea7-0c7c-40b9-a472-14c2500b9a0e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9cd62ea7-0c7c-40b9-a472-14c2500b9a0e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         title  ...                                         ingredient\n",
              "id                                              ...                                                   \n",
              "000033e39b         Dilly Macaroni Salad Recipe  ...  [elbow macaroni, american cheese, celery, gree...\n",
              "000035f7ed                            Gazpacho  ...  [tomatoes, kosher salt, red onion, green bell ...\n",
              "00003a70b1           Crunchy Onion Potato Bake  ...  [milk, water, butter, mashed potatoes, whole k...\n",
              "00004320bb  Cool 'n Easy Creamy Watermelon Pie  ...  [watermelon gelatin, boiling water, cool whip,...\n",
              "0000631d90          Easy Tropical Beef Skillet  ...  [shredded coconut, lean ground beef, fresh gar...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2min 55s (started: 2022-02-20 09:23:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brainstorming\n",
        "* not a simple sequence\n",
        "* basically sequence of\n",
        "  * ingredients\n",
        "  * set of instructions --> instruction --> words\n",
        "* maybe instead of instructions sequences, instructions could be flattened and split signs (.,!?;) also learned (in case learning sentence sequences is not possible)\n",
        "\n",
        "Maybe stacked LSTMs are a solutions\n",
        "* train how instructions in general are to be composed\n",
        "* train how instructions are combined to a set of instructions\n",
        "\n",
        "Input\n",
        "* ingredients to be used as input\n",
        "* to not train on instructions to appear according to ingredients sequence, maybe randomly shuffle ingredients but keep instruction set the same\n",
        "* \n",
        "\n",
        "https://www.youtube.com/watch?v=A9QVYOBjZdY&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S&index=5&ab_channel=TensorFlow\n",
        "\n",
        "\n",
        "## Differentiation\n",
        "* Title generation based on ingredients\n",
        "* instruction generation"
      ],
      "metadata": {
        "id": "z-ICdtLwBEM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Torch"
      ],
      "metadata": {
        "id": "lf20_SrBw-i-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwzWep0k_99",
        "outputId": "7d763fd1-72f6-4627-d6f2-3a9e5f878bb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe794af3f30>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.48 ms (started: 2022-02-20 15:06:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.data import get_tokenizer # https://pytorch.org/text/stable/data_utils.html\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# torch padding does only support constant padding (ConstantPad1d) for 1D or non-constant padding for >1D (nn.function.pad)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# keras tokenizer more powerful than torch\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize tokenizer\n",
        "# tokenizer = get_tokenizer(\"basic_english\") # pytorch\n",
        "tokenizer = Tokenizer() # keras\n",
        "\n",
        "# to be checked: necessity of punctuation (maybe reintroduce later: https://stackoverflow.com/questions/49073673/include-punctuation-in-keras-tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI-jnoQpoD5E",
        "outputId": "167ffbd6-1b19-48ed-ac91-bf284306fc40"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.85 ms (started: 2022-02-20 15:13:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "https://closeheat.com/blog/pytorch-lstm-text-generation-tutorial"
      ],
      "metadata": {
        "id": "jIhRxE1cj5ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "vi7jA5bIG2k4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a120756-d386-4f65-de54-0d8161efb2e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "time: 55.5 ms (started: 2022-02-20 09:26:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Corpus"
      ],
      "metadata": {
        "id": "m5XkLuiCIbKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = word2vec.load(dataPath + 'vocab.bin')\n",
        "ingredientDict = {}\n",
        "for voc in w2v_model.vocab:\n",
        "     # Offset by 1 so empty fields can be 0\n",
        "     ingredientDict.setdefault(voc, len(ingredientDict)+1)\n",
        "\n",
        "if 'dilly' in ingredientDict:\n",
        "  print(\"Word exists\")\n",
        "else:\n",
        "  print('vocab.bin not to be used as dict misses words') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jER6BpRl8ikx",
        "outputId": "1a9ded16-52b3-4b8f-dec9-98d8639ff072"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab.bin not to be used as dict misses words\n",
            "time: 1.19 s (started: 2022-02-20 09:26:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getCorpus(title, ingredient, instructions):\n",
        "  titleTok = text_to_word_sequence(title)\n",
        "  ingTok = text_to_word_sequence(' '.join(ingredient))\n",
        "  instTok = text_to_word_sequence(' '.join(instructions))\n",
        "  return np.array(ingTok + titleTok + instTok)\n",
        "\n",
        "corpus = np.vectorize(getCorpus, otypes=[np.ndarray])(baseFrame['title'], baseFrame['ingredient'], baseFrame['instructions'])\n",
        "corpus = np.concatenate(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyxLsHZmQ0_o",
        "outputId": "39866f68-b233-4b43-9a78-1f1cd88f92e3"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.17 s (started: 2022-02-20 15:06:09 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Sequences"
      ],
      "metadata": {
        "id": "9tmFQxxDKSW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = baseFrame.head(20).copy()\n",
        "\n",
        "def getTitleSequence(title, ingredient):\n",
        "  titleTok = text_to_word_sequence(title)\n",
        "  ingTok = text_to_word_sequence(','.join(ingredient))\n",
        "  return (ingTok + titleTok)\n",
        "\n",
        "titleSeq = np.vectorize(getTitleSequence, otypes=[np.ndarray])(test['title'], test['ingredient'])\n",
        "titleSeq[0]\n",
        "\n",
        "# xs, labels = titleSeq[:,:-1],titleSeq[:,-1]\n",
        "\n",
        "# titleSeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VbmOw8mDyOP",
        "outputId": "6adeddbd-d221-4f00-803c-922d495ae33f"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elbow',\n",
              " 'macaroni',\n",
              " 'american',\n",
              " 'cheese',\n",
              " 'celery',\n",
              " 'green',\n",
              " 'peppers',\n",
              " 'pimentos',\n",
              " 'mayonnaise',\n",
              " 'vinegar',\n",
              " 'salt',\n",
              " 'dry',\n",
              " 'dill',\n",
              " 'weed',\n",
              " 'dilly',\n",
              " 'macaroni',\n",
              " 'salad',\n",
              " 'recipe']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.62 ms (started: 2022-02-20 15:12:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTitleSequence(title, ingredient):\n",
        "  titleTok = text_to_word_sequence(title)\n",
        "  ingTok = text_to_word_sequence(','.join(ingredient))\n",
        "  return {'ings': ingTok, 'title': titleTok}\n",
        "\n",
        "titleSeq = np.vectorize(getTitleSequence, otypes=[dict])(baseFrame['title'], baseFrame['ingredient'])\n",
        "titleSeq[0]['ings']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayRlvv9Vy-CW",
        "outputId": "cd9caabb-03bf-4703-caad-19a62776d298"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elbow',\n",
              " 'macaroni',\n",
              " 'american',\n",
              " 'cheese',\n",
              " 'celery',\n",
              " 'green',\n",
              " 'peppers',\n",
              " 'pimentos',\n",
              " 'mayonnaise',\n",
              " 'vinegar',\n",
              " 'salt',\n",
              " 'dry',\n",
              " 'dill',\n",
              " 'weed']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.74 s (started: 2022-02-20 15:06:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getInstSequence(ingredient, instructions):\n",
        "  ingTok = text_to_word_sequence(','.join(ingredient))\n",
        "  instTok = text_to_word_sequence('\\n'.join(instructions))\n",
        "  return np.array(ingTok + instTok)\n",
        "\n",
        "instSeq = np.vectorize(getInstSequence, otypes=[np.ndarray])(baseFrame['ingredient'], baseFrame['instructions'])\n",
        "instSeq[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClFYJzCg2sgq",
        "outputId": "69994c60-a0ad-423a-d178-07b2bfecc035"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['elbow', 'macaroni', 'american', 'cheese', 'celery', 'green',\n",
              "       'peppers', 'pimentos', 'mayonnaise', 'vinegar', 'salt', 'dry',\n",
              "       'dill', 'weed', 'cook', 'macaroni', 'according', 'to', 'package',\n",
              "       'directions', 'drain', 'well', 'cold', 'combine', 'macaroni',\n",
              "       'cheese', 'cubes', 'celery', 'green', 'pepper', 'and', 'pimento',\n",
              "       'blend', 'together', 'mayonnaise', 'or', 'possibly', 'salad',\n",
              "       'dressing', 'vinegar', 'salt', 'and', 'dill', 'weed', 'add', 'in',\n",
              "       'to', 'macaroni', 'mix', 'toss', 'lightly', 'cover', 'and',\n",
              "       'refrigeratewell', 'serve', 'salad', 'in', 'lettuce', 'lined',\n",
              "       'bowl', 'if', 'you', 'like', 'makes', '6', 'servings'],\n",
              "      dtype='<U15')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.73 s (started: 2022-02-20 15:06:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparams"
      ],
      "metadata": {
        "id": "yTSZL7Xka-qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class hyperParams():\n",
        "  def __init__(self, epochs=10, batchSize=256, sequenceLength=4):\n",
        "    self.epochs = epochs\n",
        "    self.batchSize = batchSize\n",
        "    self.sequenceLength = sequenceLength"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGKlvcMia9Ts",
        "outputId": "86010ff5-6a87-4b6f-e15f-e75d687533ed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.8 ms (started: 2022-02-20 09:27:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding"
      ],
      "metadata": {
        "id": "dGKH6PAMQXBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XulkVNAVQWPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "WcnDjUaHKVHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data (https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)\n",
        "class TitleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, hyperparams, data):\n",
        "      self.hyperparams = hyperparams\n",
        "\n",
        "      # dataset split into word sequences required for training\n",
        "      self.wordSeq = np.vectorize(self.getTitleSequence, otypes=[np.ndarray])(data['title'], data['ingredient'])\n",
        "\n",
        "      # list of all words in dataset\n",
        "      self.words = np.concatenate(np.vectorize(self.getCorpus, otypes=[np.ndarray])(data['title'], data['ingredient'], data['instructions']))\n",
        "\n",
        "      # list of all unique words in dataset\n",
        "      self.unique = sorted(Counter(self.words), key=Counter(self.words).get, reverse=True)\n",
        "\n",
        "      # https://closeheat.com/blog/pytorch-lstm-text-generation-tutorial\n",
        "      self.index_to_word = {index: word for index, word in enumerate(unique)}\n",
        "      self.word_to_index = {word: index for index, word in enumerate(unique)}\n",
        "\n",
        "      # indexed wordSequences\n",
        "      self.idxWords = np.vectorize(self.getIndexedSeqs, otypes=[np.ndarray])(self.wordSeq)\n",
        "\n",
        "      # training requires same length sequences -->  padding\n",
        "\n",
        "    def getCorpus(self, title, ingredient, instructions):\n",
        "      titleTok = text_to_word_sequence(title)\n",
        "      ingTok = text_to_word_sequence(','.join(ingredient))\n",
        "      instTok = text_to_word_sequence('\\n'.join(instructions))\n",
        "      return np.array(ingTok + titleTok + instTok)\n",
        "\n",
        "    def getTitleSequence(self, title, ingredient):\n",
        "      titleTok = text_to_word_sequence(title)\n",
        "      ingTok = text_to_word_sequence(','.join(ingredient))\n",
        "      return {'ings': ingTok, 'title': titleTok}\n",
        "\n",
        "    def getIndexedSeqs(self, seq):\n",
        "      ingTok = np.vectorize(self.word_to_index.get)(seq['ings'])\n",
        "      titleTok = np.vectorize(self.word_to_index.get)(seq['title'])\n",
        "      return {'ings': ingTok, 'title': titleTok}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxWords)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # tuple of input (ingredients) and label (title)\n",
        "        return (\n",
        "            torch.tensor(self.idxWords[index]['ings'], device=device),\n",
        "            torch.tensor(self.idxWords[index]['title'], device=device)\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRKA1xo1thoy",
        "outputId": "b4d6f128-904f-4c0f-b94b-bc5c0b59904b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 28.7 ms (started: 2022-02-20 11:04:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "\n",
        "        n_vocab = len(dataset.unique)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
      ],
      "metadata": {
        "id": "6skcY1-tuROl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c2f01d-b02f-431e-e6a8-2558a29965f5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.78 ms (started: 2022-02-20 09:27:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, model):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=dataset.hyperparams.batchSize)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(dataset.hyperparams.epochs):\n",
        "        state_h, state_c = model.init_state(dataset.hyperparams.sequenceLength)\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "    #         y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "    #         loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "    #         state_h = state_h.detach()\n",
        "    #         state_c = state_c.detach()\n",
        "\n",
        "    #         loss.backward()\n",
        "    #         optimizer.step()\n",
        "\n",
        "    #         print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n06flUjfkFNh",
        "outputId": "650daab7-f821-4aad-f21e-7a3de91fe337"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.17 ms (started: 2022-02-20 10:32:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov7EPe_eqmbP",
        "outputId": "e183e9d5-ca7d-4606-cf33-56e0e65d3a89"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.49 ms (started: 2022-02-20 09:27:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution"
      ],
      "metadata": {
        "id": "fdDLkBBLbNiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titleSet = TitleDataset(hyperParams(), baseFrame)\n",
        "model = Model(titleSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWe4t2xp_Ieg",
        "outputId": "d729c737-5ed3-49c4-e78b-41ddb5ee2f49"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 37.7 s (started: 2022-02-20 11:04:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(titleSet, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL4vqYn0aXXk",
        "outputId": "f86c5a3a-9414-44e4-d2fc-dc95e1e722b5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.03 ms (started: 2022-02-20 10:32:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(predict(dataset, model, text='Knock knock. Whos there?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtWOfGAu_HwF",
        "outputId": "2428fc72-e6e1-489e-fcc1-69098dc2a080"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 749 µs (started: 2022-02-20 09:27:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i_batch, sample_batched in enumerate(DataLoader(titleSet, batch_size=titleSet.hyperparams.batchSize)):\n",
        "    print('hello')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "oplEqqAleNha",
        "outputId": "f5ebe86a-a8f1-4bf8-9036-c328790a6b11"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-091e2756fbb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitleSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitleSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [22] at entry 0 and [27] at entry 1"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 82.7 ms (started: 2022-02-20 11:05:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titleSet[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_r77YvXsLVY",
        "outputId": "465d85f6-2212-489c-8cc8-e20037a17b62"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1852,  734,    0, 1679,   23,    0,  218,    0,  104,  175,    0, 2573,\n",
              "           0,  310,    0,  122,    0,   13,    0,  115,  521, 1493],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.93 ms (started: 2022-02-20 11:23:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "V0wc_ivZ2DRJ",
        "outputId": "aa4ebeea-27f7-4f53-def9-3823343d7f9e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-8b144750666e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pad sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# max_sequence_len = max([len(x) for x in input_sequences])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: array() got an unexpected keyword argument 'maxlen'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.94 ms (started: 2022-02-20 11:23:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "data = data.reshape((1, 10, 1))\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCVSjVgQ3srn",
        "outputId": "4486ab7b-31cb-4312-a626-c3d7cf6229df"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 10, 1)\n",
            "time: 2.23 ms (started: 2022-02-20 11:45:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9_oPy9_j85NI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}