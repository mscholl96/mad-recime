{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\02_Studium\\SBX\\mad-recime\\network\\LSTM\\src\\nlp_utils\\trainTitle.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/02_Studium/SBX/mad-recime/network/LSTM/src/nlp_utils/trainTitle.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/02_Studium/SBX/mad-recime/network/LSTM/src/nlp_utils/trainTitle.ipynb#ch0000011?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/02_Studium/SBX/mad-recime/network/LSTM/src/nlp_utils/trainTitle.ipynb#ch0000011?line=3'>4</a>\u001b[0m rootDir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/content/drive/MyDrive/\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "rootDir = '/content/drive/MyDrive/'\n",
    "\n",
    "TIMESTAMP = '2022_03_30'\n",
    "\n",
    "dataPath = rootDir + 'TP2/Datasets/Recipe1M/' + TIMESTAMP\n",
    "tarPath = rootDir + 'Colab Notebooks/recime/data/' + TIMESTAMP\n",
    "weightDir = rootDir + 'Colab Notebooks/recime/weights/'\n",
    "logDir = rootDir + 'Colab Notebooks/recime/runs/titleTrainer/'\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(rootDir + 'Colab Notebooks/recime/LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/02_Studium/SBX/mad-recime/network/LSTM')\n",
    "\n",
    "tarPath = 'D:/02_Studium/SBX/mad-recime/data/2022_03_19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "\n",
    "import random\n",
    "import re\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.pytorch_lightning import (\n",
    "    TuneReportCallback,\n",
    "    TuneReportCheckpointCallback,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nlp_utils.model as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nlp_utils.data_module as data_module\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed to get consistent results, deactivate if random results are wanted\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\02_Studium/SBX/mad-recime/network/LSTM\\src\\preProc.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseFrame = baseFrame.append(pd.read_pickle(dataSetSplits[split]))\n",
      "D:\\02_Studium/SBX/mad-recime/network/LSTM\\src\\preProc.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseFrame = baseFrame.append(pd.read_pickle(dataSetSplits[split]))\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\Users\\Hannes\\miniconda3\\envs\\madEnv\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | embed     | Embedding        | 171 K \n",
      "1 | lstm      | LSTM             | 571 K \n",
      "2 | linear    | Linear           | 147 K \n",
      "3 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "889 K     Trainable params\n",
      "0         Non-trainable params\n",
      "889 K     Total params\n",
      "3.560     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "importlib.reload(models)\n",
    "importlib.reload(data_module)\n",
    "\n",
    "from config import create_config\n",
    "\n",
    "config = create_config({})\n",
    "\n",
    "titleMod = data_module.TitleDataModule(tarPath)\n",
    "titleMod.setup()\n",
    "\n",
    "config['vocabSize'] = titleMod.vocab_size\n",
    "\n",
    "model = models.EmbedLSTM(config)\n",
    "\n",
    "trainer = Trainer(max_epochs=config['epochs'])\n",
    "trainer.fit(model, titleMod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = MNISTDataModule(my_path)\n",
    "# model = LitClassifier()\n",
    "\n",
    "# trainer = Trainer()\n",
    "# trainer.fit(model, mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.05,\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    "    mode=\"min\",\n",
    "    divergence_threshold=3.00,\n",
    ")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "save_folder = os.path.join(cwd, \"../logs/StancePrediction_SemEval\")\n",
    "\n",
    "\n",
    "class MyPrintingCallback(Callback):\n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        print(\"Starting to train!\")\n",
    "\n",
    "    def on_fit_end(self, trainer, pl_module):\n",
    "        print(\"Finished training\")\n",
    "\n",
    "    def on_test_start(self, trainer, pl_module):\n",
    "        print(\"Start to test\")\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        print(\"Finished testing\")\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_epoch_stance_F1\",\n",
    "    filename=\"{epoch}-{val_loss:.2f}-{val_epoch_stance_F1:.2f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "callback = TuneReportCallback(\n",
    "    {\"loss\": \"val_loss\", \"mean_F1\": \"val_epoch_F1\"}, on=\"validation_end\"\n",
    ")\n",
    "\n",
    "\n",
    "# training loop that tests out different hyperparameters and saves the results into the log folder\n",
    "def train_tune(config, callbacks, epochs=10, gpus=0):\n",
    "    data_module = TitleDateModule(num_workers=4, config=config)\n",
    "    data_module.setup(\"\")\n",
    "    config[\"vocabSize\"] = data_module.vocab_size\n",
    "    model = CustomDistilBertModel(config)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=gpus,\n",
    "        log_every_n_steps=1,\n",
    "        flush_logs_every_n_steps=1,\n",
    "        callbacks=callbacks,\n",
    "        deterministic=True,\n",
    "        default_root_dir=save_folder,\n",
    "        max_epochs=epochs,\n",
    "    )  # gradient_clip_val=0.5, stochastic_weight_avg=True, check_val_every_n_epoch=10, num_sanity_val_steps=2, overfit_batches=0.01\n",
    "    # logger=TensorBoardLogger(save_dir=tune.get_trial_dir(), name=\"\", version=\".\"),\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    # might not be called due to scheduler and reporter which cancel training early if results don't look promising\n",
    "    trainer.test(model, datamodule=data_module)\n",
    "\n",
    "\n",
    "# config with radom sampling for learning rate and batch size\n",
    "config = {\n",
    "    \"dataset_path\": \"../../data/raw/SemEval/\",\n",
    "    \"learning_rate\": tune.sample_from(lambda: abs(random.gauss(1e-3, 1e-3))),\n",
    "    \"batch_size\": tune.choice([16, 32, 64, 128]),\n",
    "    \"epochs\": 20,\n",
    "    \"num_trials\": 50,\n",
    "}\n",
    "\n",
    "\n",
    "callbacks = [MyPrintingCallback(), checkpoint_callback, callback]\n",
    "\n",
    "scheduler = ASHAScheduler(max_t=config[\"epochs\"], grace_period=1, reduction_factor=2)\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=[\"lr\", \"batch_size\"],\n",
    "    metric_columns=[\"loss\", \"mean_accuracy\", \"training_iteration\"],\n",
    ")\n",
    "\n",
    "# ray.init(local_mode=True, num_cpus=4, num_gpus=0)  # for debugging\n",
    "\n",
    "# create versioning for multiple runs\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split(\"(\\d+)\", text)]\n",
    "\n",
    "\n",
    "log_dir = \"../logs/StancePrediction_SemEval/lightning_logs/\"\n",
    "log_path = os.path.join(path, log_dir)\n",
    "os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "ver = os.listdir(os.path.join(path, log_dir))\n",
    "ver.sort(key=natural_keys)\n",
    "if ver:\n",
    "    version = int(ver[-1].split(\"_\", 2)[-1]) + 1\n",
    "else:\n",
    "    version = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start hyperparameter optimization\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(\n",
    "        train_tune, callbacks=callbacks, epochs=config[\"epochs\"], gpus=0\n",
    "    ),\n",
    "    config=config,\n",
    "    num_samples=config[\"num_trials\"],\n",
    "    local_dir=os.path.join(path, \"../logs/StancePrediction_SemEval/ray_results\"),\n",
    "    name=\"version_\" + str(version),\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    ")\n",
    "# metric=\"loss\", mode=\"min\", scheduler=scheduler, progress_reporter=reporter\n",
    "\n",
    "# get some information from the optimization\n",
    "best_trial = analysis.best_trial  # Get best trial\n",
    "best_config = analysis.best_config  # Get best trial's hyperparameters\n",
    "best_logdir = analysis.best_logdir  # Get best trial's logdir\n",
    "best_checkpoint = analysis.best_checkpoint  # Get best trial's best checkpoint\n",
    "best_result = analysis.best_result  # Get best trial's last results\n",
    "best_result_df = analysis.best_result_df  # Get best result as pandas dataframe\n",
    "\n",
    "# Get a dataframe with the last results for each trial\n",
    "df_results = analysis.results_df\n",
    "\n",
    "# Get a dataframe of results for a specific score or mode\n",
    "df = analysis.dataframe(metric=\"loss\", mode=\"min\")\n",
    "# df2 = analysis.dataframe(metric=\"val_epoch_F1\", mode=\"max\") # check how to include multiple metrics\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "\n",
    "# save dataframe with results from hyperparameter search as csv?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a78eccb40e61b98140ae1027d27413ec0b4019861790215488952e2bb9987dd2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('madEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
