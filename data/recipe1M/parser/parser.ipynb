{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "legF7h2yMvy5"
      },
      "source": [
        "# Recipe1M parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "INSDCTl3Mvy-",
        "outputId": "658a8113-409c-4962-cc60-6fad8b6ad392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.7/dist-packages (0.7.9)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (from quantulum3) (0.5.10)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from quantulum3) (2.1.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->quantulum3) (0.6.2)\n",
            "Requirement already satisfied: stemming in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install quantulum3\n",
        "!pip install stemming\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from recipe import Recipe\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add GDrive\n",
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive/')\n",
        "sys.path.append('/content/drive/My Drive/Datasets/Recipe1M/') ## Place correct Link HERE !!! ##"
      ],
      "metadata": {
        "id": "c19YiEPuNDjN",
        "outputId": "96fd5593-be2f-42d4-fd0b-f56e6bfe5b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaAYmrtLMvy_"
      },
      "source": [
        "## Recipe1M data\n",
        "Recipe1M comes with various json files containing crawled recipes from the web. For our project, two of them are interesting:\n",
        "* layer1.json: Contains all recipes to their full extend\n",
        "  \n",
        "  ![layer1](https://github.com/mscholl96/mad-recime/blob/recipe1M-parser/data/recipe1M/dataset-analysis/layer1_puml.png?raw=1)\n",
        "\n",
        "* det_ingrs.json: Only contains recipe ID, parsed ingredients and validity flag for parsing \n",
        "  \n",
        "  ![det_ingrs](https://github.com/mscholl96/mad-recime/blob/recipe1M-parser/data/recipe1M/dataset-analysis/det_ingrs_puml.png?raw=1)\n",
        "\n",
        "In our first attempt we want to make use of the parsed ingredient list and only consider recipes, where all ingredients are marked valid. The parsed ingredients don't contain amounts, so our parser has to kind of merge content of both files. Extracting ingredients from one and their amount and unit from the other file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rllGc9GMvzA"
      },
      "source": [
        "## Preprocessing\n",
        "Removal of all invalid sets from ingredient and full data json to reduce memory. Use pickle instead of json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jFZgOjpsMvzB",
        "outputId": "ba012a57-08c8-4290-88cb-943d8f187a8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 869656 entries, 1 to 1029719\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   valid        869656 non-null  object\n",
            " 1   id           869656 non-null  object\n",
            " 2   ingredients  869656 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 26.5+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 869656 entries, 1 to 1029719\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   ingredients   869656 non-null  object\n",
            " 1   url           869656 non-null  object\n",
            " 2   partition     869656 non-null  object\n",
            " 3   title         869656 non-null  object\n",
            " 4   id            869656 non-null  object\n",
            " 5   instructions  869656 non-null  object\n",
            "dtypes: object(6)\n",
            "memory usage: 46.4+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 869656 entries, 1 to 1029719\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   ingredients   869656 non-null  object\n",
            " 1   url           869656 non-null  object\n",
            " 2   partition     869656 non-null  object\n",
            " 3   title         869656 non-null  object\n",
            " 4   id            869656 non-null  object\n",
            " 5   instructions  869656 non-null  object\n",
            "dtypes: object(6)\n",
            "memory usage: 46.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Removal of all elements in ingredient json which contain invalid entries according to the data set\n",
        "ingredient_data = pd.read_json('/content/drive/My Drive/Datasets/Recipe1M/det_ingrs.json')\n",
        "recipe_raw_data = pd.read_json('/content/drive/My Drive/Datasets/Recipe1M/layer1.json')\n",
        "\n",
        "indices = []\n",
        "i = 0\n",
        "for row in ingredient_data.valid:\n",
        "    if any(x == False for x in row):\n",
        "        indices.append(i)\n",
        "    i += 1\n",
        "\n",
        "# Frame of ids that have to be dropped from raw data\n",
        "drop_ids = pd.DataFrame(ingredient_data.iloc[indices]['id'])\n",
        "\n",
        "# Drop indices from ingredient data\n",
        "ingredient_data.drop(indices, inplace=True)\n",
        "ingredient_data.info()\n",
        "\n",
        "# Remove data from raw recipes where id matches\n",
        "recipe_mod = recipe_raw_data[~recipe_raw_data.id.isin(drop_ids.id)]\n",
        "recipe_mod.info()\n",
        "\n",
        "# Remove fractions from raw ingredients\n",
        "fractionRegex = re.compile(\"[0-9]+/[0-9]+\")\n",
        "for _, recipe in recipe_mod.iterrows():\n",
        "    ingredients_mod = []\n",
        "    for ingredient in recipe['ingredients']:\n",
        "        ingredient_mod = \"\"\n",
        "        for word in ingredient['text'].split(' '):\n",
        "            match = re.match(fractionRegex, word)\n",
        "            if match:\n",
        "                numbers = match.group(0).split('/')\n",
        "\n",
        "                float_representation = int(numbers[0])/int(numbers[1])\n",
        "                ingredient_mod += f'{float_representation} '\n",
        "            else:\n",
        "                ingredient_mod += f'{word} '\n",
        "        ingredients_mod.append({'text': ingredient_mod})\n",
        "    recipe['ingredients'] = ingredients_mod\n",
        "\n",
        "recipe_mod.info()\n",
        "\n",
        "# TODO: Replace unparseable stuff like \"c.\" --> cup \n",
        "\n",
        "# Save data to pickle (it's faster)\n",
        "ingredient_data.to_pickle('/content/drive/My Drive/Datasets/Recipe1M/det_ingrs_valid.pkl')\n",
        "recipe_mod.to_pickle('/content/drive/My Drive/Datasets/Recipe1M/layer1_valid.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2CdKidCMvzD"
      },
      "source": [
        "## Actual parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwWV1pDuMvzD",
        "outputId": "c47eac96-cdd5-4f74-eb2a-4ee4c3530638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of recipes: 869656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "2022-01-16 20:12:48,379 --- The classifier was built using a different scikit-learn version (=0.24.2, !=1.0.2). The disambiguation tool could behave unexpectedly. Consider running classifier.train_classfier()\n"
          ]
        }
      ],
      "source": [
        "recipes = []\n",
        "data = pd.read_pickle('/content/drive/My Drive/Datasets/Recipe1M/layer1_valid.pkl')\n",
        "num_recipes = len(data)\n",
        "print(f'Total number of recipes: {num_recipes}')\n",
        "# Use id as index for easy access\n",
        "data = data.set_index('id')\n",
        "\n",
        "ingredient_data = pd.read_pickle('/content/drive/My Drive/Datasets/Recipe1M/det_ingrs_valid.pkl')\n",
        "for _, row in ingredient_data.iterrows():\n",
        "    recipe = Recipe(row['id'])\n",
        "    \n",
        "    # Continue if parser didn't parse\n",
        "    if False == recipe.parse_ingredients(row['ingredients']):\n",
        "        continue\n",
        "    \n",
        "    # Find raw recipe by id\n",
        "    raw_recipe = data.loc[recipe.id]\n",
        "    recipe.get_ingredient_amounts(raw_recipe['ingredients'])\n",
        "    \n",
        "    # Continue if parser didn't parse\n",
        "    if False == recipe.parse_instructions(raw_recipe['instructions']):\n",
        "        continue\n",
        "\n",
        "    recipe.title = raw_recipe['title']\n",
        "    recipes.append(recipe)\n",
        "\n",
        "# Create data frame in the end (according to Stackoverflow this is faster)                \n",
        "df = pd.DataFrame([vars(r) for r in recipes])\n",
        "df = df.set_index('id')\n",
        "df.to_pickle('/content/drive/My Drive/Datasets/Recipe1M/recipes_valid.pkl')\n",
        "df.to_json('/content/drive/My Drive/Datasets/Recipe1M/recipes_valid.json')\n",
        "df.head(10)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "0c8a1bae5d334f5a25fa0c8c26e12c4821d7dc0816c2aa0955ea6e9dc2769bbc"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "parser.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}